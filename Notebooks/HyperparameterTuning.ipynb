{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 17:01:18.710841: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-01 17:01:20.590997: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9373] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-01 17:01:20.592542: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-01 17:01:20.784125: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1534] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-01 17:01:21.147261: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "from astromcad.astromcad import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names_load = ['lc_classnum_Ia-norm_90.pickle',\n",
    " 'lc_classnum_Ia-91bg_67.pickle',\n",
    " 'lc_classnum_Iax_52.pickle',\n",
    "'lc_classnum_Ib.pickle',\n",
    " 'lc_classnum_Ic.pickle',\n",
    " 'lc_classnum_Ic-BL.pickle',\n",
    " 'lc_classnum_II.pickle',\n",
    " 'lc_classnum_IIn.pickle',\n",
    " 'lc_classnum_IIb.pickle',\n",
    " 'lc_classnum_TDE_64.pickle',\n",
    " 'lc_classnum_SLSN-I_60.pickle',\n",
    " 'lc_classnum_AGN_70_old.pickle',\n",
    " 'lc_classnum_CART_63_old.pickle',\n",
    " 'lc_classnum_Kilonova_99.pickle',\n",
    "'lc_classnum_PISN_61_old.pickle',\n",
    "'lc_classnum_ILOT_62_old.pickle',\n",
    "'lc_classnum_uLens-BSR_90_old.pickle']\n",
    "\n",
    "file_names = ['lc_classnum_Ia.pickle',\n",
    " 'lc_classnum_Ia-91bg.pickle',\n",
    " 'lc_classnum_Iax.pickle',\n",
    "'lc_classnum_Ib.pickle',\n",
    " 'lc_classnum_Ic.pickle',\n",
    " 'lc_classnum_Ic-BL.pickle',\n",
    " 'lc_classnum_II.pickle',\n",
    " 'lc_classnum_IIn.pickle',\n",
    " 'lc_classnum_IIb.pickle',\n",
    " 'lc_classnum_TDE.pickle',\n",
    " 'lc_classnum_SLSN-I.pickle',\n",
    " 'lc_classnum_AGN_old.pickle',\n",
    " 'lc_classnum_CART_old.pickle',\n",
    " 'lc_classnum_Kilonova.pickle',\n",
    "'lc_classnum_PISN_old.pickle',\n",
    "'lc_classnum_ILOT_old.pickle',\n",
    "'lc_classnum_uLens-BSR.pickle']\n",
    "\n",
    "classes = ['SNIa', 'SNIa-91bg', 'SNIax', 'SNIb', 'SNIc', 'SNIc-BL', 'SNII', 'SNIIn', 'SNIIb', 'TDE', 'SLSN-I', 'AGN', 'CaRT', 'KNe', 'PISN', 'ILOT', 'uLens-BSR']\n",
    "\n",
    "file_to_class = dict(zip(file_names, classes))\n",
    "\n",
    "\n",
    "class_to_file = {v: k for k, v in file_to_class.items()}\n",
    "class_to_file['SNIa-x'] = class_to_file['SNIax']\n",
    "class_to_file['SNIa-norm'] = class_to_file['SNIa']\n",
    "\n",
    "anom_classes = file_names[-5:]\n",
    "non_anom_classes = file_names[:-5]\n",
    "\n",
    "\n",
    "color = ['r', 'g', 'y', 'b', 'purple', 'orange', 'gray', 'k', 'm', 'c', 'brown', 'olive']\n",
    "colors = color\n",
    "\n",
    "font = {'size'   : 17}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "anom_classes = [file_to_class[i] for i in anom_classes]\n",
    "non_anom_classes = [file_to_class[i] for i in non_anom_classes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(save_path , obj):\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "target = load(\"data/target\")\n",
    "x_data = load(\"data/x_data\")\n",
    "host_galaxy_info = load(\"data/host_galaxy_info\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656\n"
     ]
    }
   ],
   "source": [
    "valid = [False] * len(target)\n",
    "\n",
    "for class_ in np.unique(target):\n",
    "    cnt = 0\n",
    "    for i in range(len(target)):\n",
    "\n",
    "        if (target[i] == class_):\n",
    "            valid[i] = True\n",
    "            cnt+=1\n",
    "        if (cnt == 13000): # cut down\n",
    "            break\n",
    "for i in range(len(target) - 1, -1, -1):\n",
    "    if not valid[i]:\n",
    "        del target[i]\n",
    "        del x_data[i]\n",
    "        del host_galaxy_info[i]\n",
    "\n",
    "lengths = []\n",
    "\n",
    "for lc in x_data:\n",
    "    lengths.append(len(lc))\n",
    "\n",
    "ntimesteps = np.max(lengths)\n",
    "\n",
    "print(ntimesteps)\n",
    "\n",
    "# Pad for TF masking layer and time dilation\n",
    "def dilate(vals, red):\n",
    "    return ((((vals * 100) - 30) / (1 + red)) + 30) / 100 # unscale time then correct\n",
    "\n",
    "\n",
    "for ind in range(len(x_data)):\n",
    "  x_data[ind][:, 1] = dilate(x_data[ind][:, 1], host_galaxy_info[ind][0])\n",
    "  x_data[ind] = np.pad(x_data[ind], ((0, ntimesteps - len(x_data[ind])), (0, 0)))\n",
    "# x_data = np.array(x_data)\n",
    "# Split data\n",
    "\n",
    "y_data_anom = []\n",
    "y_data_norm = []\n",
    "x_data_norm = []\n",
    "x_data_anom = []\n",
    "host_gal_anom = []\n",
    "host_gal = []\n",
    "\n",
    "for i in range(len(target)):\n",
    "\n",
    "    if (file_to_class[target[i]] in anom_classes):\n",
    "        x_data_anom.append(x_data[i])\n",
    "        y_data_anom.append(target[i])\n",
    "        host_gal_anom.append(host_galaxy_info[i])\n",
    "\n",
    "    else:\n",
    "        x_data_norm.append(x_data[i])\n",
    "        y_data_norm.append(target[i])\n",
    "        host_gal.append(host_galaxy_info[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lc_classnum_AGN_old.pickle' 'lc_classnum_II.pickle'\n",
      " 'lc_classnum_IIb.pickle' 'lc_classnum_IIn.pickle'\n",
      " 'lc_classnum_Ia-91bg.pickle' 'lc_classnum_Ia.pickle'\n",
      " 'lc_classnum_Iax.pickle' 'lc_classnum_Ib.pickle'\n",
      " 'lc_classnum_Ic-BL.pickle' 'lc_classnum_Ic.pickle'\n",
      " 'lc_classnum_SLSN-I.pickle' 'lc_classnum_TDE.pickle']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(95182, 656, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# One-hot Encoding\n",
    "print(np.unique(y_data_norm))\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "y_data_norm = enc.fit_transform(np.array(y_data_norm).reshape(-1, 1)).todense()\n",
    "# Train-test split\n",
    "\n",
    "X_train, X_test, host_gal_train, host_gal_test, y_train, y_test = train_test_split(x_data_norm, host_gal, y_data_norm, random_state = 40, test_size = 0.1)\n",
    "X_train, X_val, host_gal_train, host_gal_val, y_train, y_val = train_test_split(X_train, host_gal_train, y_train, random_state = 40, test_size = 1/9)\n",
    "class_weights = {i : 0 for i in range(y_train.shape[1])}\n",
    "\n",
    "for value in y_train:\n",
    "  class_weights[np.argmax(value)]+=1\n",
    "\n",
    "for id in class_weights.keys():\n",
    "  class_weights[id] = len(y_train) / class_weights[id]\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "host_gal_train = np.array(host_gal_train)\n",
    "host_gal_test = np.array(host_gal_test)\n",
    "host_gal_val = np.array(host_gal_val)\n",
    "\n",
    "y_train = np.squeeze(y_train)\n",
    "y_val = np.squeeze(y_val)\n",
    "y_test = np.squeeze(y_test)\n",
    "y_data_anom = np.squeeze(y_data_anom)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = enc.transform(np.array([class_to_file[i] for i in non_anom_classes]).reshape(-1, 1))\n",
    "\n",
    "ordered_class_names = [-1 for i in range(len(non_anom_classes))]\n",
    "\n",
    "for ind, i in enumerate(dummy.todense()):\n",
    "    ordered_class_names[np.argmax(i)] = non_anom_classes[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AGN',\n",
       " 'SNII',\n",
       " 'SNIIb',\n",
       " 'SNIIn',\n",
       " 'SNIa-91bg',\n",
       " 'SNIa',\n",
       " 'SNIax',\n",
       " 'SNIb',\n",
       " 'SNIc-BL',\n",
       " 'SNIc',\n",
       " 'SLSN-I',\n",
       " 'TDE']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, TimeDistributed, Dense, Masking, concatenate, GRU, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from math import dist\n",
    "import keras\n",
    "def make_classifier_model(latent_size):\n",
    "\n",
    "    num_classes = len(class_weights)\n",
    "    n_features = 4\n",
    "\n",
    "    input_1 = Input((ntimesteps, n_features), name='lc')  # X.shape = (Nobjects, Ntimesteps, 4) CHANGE\n",
    "\n",
    "    masking_input1 = Masking(mask_value=0.)(input_1)\n",
    "\n",
    "    lstm1 = GRU(100, return_sequences=True, activation='tanh')(masking_input1)\n",
    "    lstm2 = GRU(100, return_sequences=False, activation='tanh')(lstm1)\n",
    "\n",
    "    dense1 = Dense(100, activation='tanh')(lstm2)\n",
    "\n",
    "    input_2 = Input(shape = (2, ), name='host') # CHANGE\n",
    "\n",
    "    dense2 = Dense(10)(input_2)\n",
    "\n",
    "    merge1 = concatenate([dense1, dense2])\n",
    "\n",
    "    dense3 = Dense(100, activation='relu')(merge1)\n",
    "\n",
    "    dense4 = Dense(latent_size, activation='relu', name='latent')(dense3)\n",
    "\n",
    "    output = Dense(num_classes, activation='softmax')(dense4)\n",
    "\n",
    "    model = keras.Model(inputs=[input_1, input_2], outputs=output)\n",
    "\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def make_classifier_no_host(latent_size):\n",
    "\n",
    "    num_classes = len(class_weights)\n",
    "    n_features = 4\n",
    "\n",
    "    input_1 = Input((ntimesteps, n_features), name='lc')  # X.shape = (Nobjects, Ntimesteps, 4) CHANGE\n",
    "\n",
    "    masking_input1 = Masking(mask_value=0.)(input_1)\n",
    "\n",
    "    lstm1 = GRU(100, return_sequences=True, activation='tanh')(masking_input1)\n",
    "    lstm2 = GRU(100, return_sequences=False, activation='tanh')(lstm1)\n",
    "\n",
    "    dense1 = Dense(100, activation='tanh')(lstm2)\n",
    "\n",
    "#     input_2 = Input(shape = (2, ), name='host') # CHANGE\n",
    "\n",
    "#     dense2 = Dense(10)(input_2)\n",
    "\n",
    "#     merge1 = concatenate([dense1, dense2])\n",
    "\n",
    "#     dense3 = Dense(100, activation='relu')(merge1)\n",
    "\n",
    "    dense4 = Dense(latent_size, activation='relu', name='latent')(dense1)\n",
    "\n",
    "    output = Dense(num_classes, activation='softmax')(dense4)\n",
    "\n",
    "    model = keras.Model(inputs=[input_1], outputs=output)\n",
    "\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure feature correlation of the latent space\n",
    "\n",
    "def train_model(latent_size, host=True):\n",
    "    if (host):\n",
    "        model = make_classifier_model(latent_size) # HERE YOU CAN CHANGE THE LATENT SPACE SIZE\n",
    "    else:\n",
    "        model = make_classifier_no_host(latent_size) # HERE YOU CAN CHANGE THE LATENT SPACE SIZE\n",
    "        \n",
    "    early_stopping = EarlyStopping(\n",
    "                                  patience=5,\n",
    "                                  min_delta=0.001,                               \n",
    "                                  monitor=\"val_loss\",\n",
    "                                  restore_best_weights=True\n",
    "                                  )\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        if (host):\n",
    "            history = model.fit(x = [X_train, host_gal_train], validation_data=([X_val, host_gal_val], y_val), y = y_train, epochs=40, batch_size = 128, class_weight = class_weights, callbacks=[early_stopping])\n",
    "        else:\n",
    "            history = model.fit(x = [X_train], validation_data=([X_val], y_val), y = y_train, epochs=40, batch_size = 128, class_weight = class_weights, callbacks=[early_stopping])\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, roc_curve, roc_auc_score, auc\n",
    "single_test = [np.argmax(i) for i in y_test]\n",
    "\n",
    "def get_auroc(predictions, single_test):\n",
    "    rocs = []\n",
    "    for i in range(len(non_anom_classes)):\n",
    "      fpr, tpr, _ = roc_curve(y_true = single_test, y_score = predictions[:, i], pos_label = i)\n",
    "      rocs.append(round(auc(fpr, tpr), 2))\n",
    "    \n",
    "    return np.array(rocs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "szs = [9, 20, 30, 40, 60, 70, 80, 90, 100, 125, 150, 175]\n",
    "\n",
    "all = list(range(10, 260, 10))\n",
    "rec = []\n",
    "done = []\n",
    "cls_perf = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372/372 [==============================] - 2s 6ms/step - loss: 0.4455 - accuracy: 0.8448\n"
     ]
    }
   ],
   "source": [
    "cls_perf = [model.evaluate([X_test, host_gal_test],y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 24ms/step - loss: 19.8633 - accuracy: 0.4336 - val_loss: 1.1842 - val_accuracy: 0.5767\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 13.1327 - accuracy: 0.6402 - val_loss: 0.8960 - val_accuracy: 0.6775\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 10.8057 - accuracy: 0.7058 - val_loss: 0.7575 - val_accuracy: 0.7290\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 9.4555 - accuracy: 0.7430 - val_loss: 0.6774 - val_accuracy: 0.7432\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 8.6719 - accuracy: 0.7669 - val_loss: 0.6450 - val_accuracy: 0.7616\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.9533 - accuracy: 0.7877 - val_loss: 0.5722 - val_accuracy: 0.7902\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.4404 - accuracy: 0.8020 - val_loss: 0.5309 - val_accuracy: 0.8104\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.1411 - accuracy: 0.8123 - val_loss: 0.5284 - val_accuracy: 0.8081\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.7694 - accuracy: 0.8231 - val_loss: 0.4807 - val_accuracy: 0.8258\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.4787 - accuracy: 0.8290 - val_loss: 0.5311 - val_accuracy: 0.8053\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.2384 - accuracy: 0.8349 - val_loss: 0.4641 - val_accuracy: 0.8274\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.0522 - accuracy: 0.8390 - val_loss: 0.5242 - val_accuracy: 0.8052\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.8530 - accuracy: 0.8444 - val_loss: 0.5161 - val_accuracy: 0.8148\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.6244 - accuracy: 0.8485 - val_loss: 0.4575 - val_accuracy: 0.8359\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.4675 - accuracy: 0.8545 - val_loss: 0.4639 - val_accuracy: 0.8317\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.3167 - accuracy: 0.8556 - val_loss: 0.4651 - val_accuracy: 0.8317\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.1945 - accuracy: 0.8580 - val_loss: 0.4104 - val_accuracy: 0.8527\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.0607 - accuracy: 0.8617 - val_loss: 0.4503 - val_accuracy: 0.8383\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.9278 - accuracy: 0.8648 - val_loss: 0.4143 - val_accuracy: 0.8502\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.7734 - accuracy: 0.8674 - val_loss: 0.4417 - val_accuracy: 0.8435\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.6398 - accuracy: 0.8698 - val_loss: 0.4522 - val_accuracy: 0.8396\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.5678 - accuracy: 0.8723 - val_loss: 0.4203 - val_accuracy: 0.8499\n",
      "2975/2975 [==============================] - 18s 5ms/step\n",
      "372/372 [==============================] - 2s 6ms/step - loss: 0.4151 - accuracy: 0.8443\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 24ms/step - loss: 20.1623 - accuracy: 0.4224 - val_loss: 1.2805 - val_accuracy: 0.5448\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 13.4702 - accuracy: 0.6284 - val_loss: 0.9146 - val_accuracy: 0.6783\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 10.9293 - accuracy: 0.6982 - val_loss: 0.7444 - val_accuracy: 0.7289\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 9.5257 - accuracy: 0.7437 - val_loss: 0.6439 - val_accuracy: 0.7645\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 8.5311 - accuracy: 0.7728 - val_loss: 0.5825 - val_accuracy: 0.7859\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.9433 - accuracy: 0.7909 - val_loss: 0.5854 - val_accuracy: 0.7859\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.4292 - accuracy: 0.8052 - val_loss: 0.4828 - val_accuracy: 0.8231\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.1256 - accuracy: 0.8139 - val_loss: 0.5207 - val_accuracy: 0.8119\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.7705 - accuracy: 0.8222 - val_loss: 0.4827 - val_accuracy: 0.8248\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.4201 - accuracy: 0.8311 - val_loss: 0.4536 - val_accuracy: 0.8348\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.2833 - accuracy: 0.8355 - val_loss: 0.4939 - val_accuracy: 0.8245\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.0275 - accuracy: 0.8409 - val_loss: 0.4411 - val_accuracy: 0.8410\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.8707 - accuracy: 0.8448 - val_loss: 0.4685 - val_accuracy: 0.8301\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.6532 - accuracy: 0.8508 - val_loss: 0.4199 - val_accuracy: 0.8485\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.4562 - accuracy: 0.8537 - val_loss: 0.4254 - val_accuracy: 0.8443\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.3529 - accuracy: 0.8569 - val_loss: 0.4188 - val_accuracy: 0.8469\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.1648 - accuracy: 0.8610 - val_loss: 0.4045 - val_accuracy: 0.8554\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.0255 - accuracy: 0.8642 - val_loss: 0.4493 - val_accuracy: 0.8386\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.8904 - accuracy: 0.8655 - val_loss: 0.4287 - val_accuracy: 0.8411\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.7016 - accuracy: 0.8693 - val_loss: 0.4030 - val_accuracy: 0.8529\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.6502 - accuracy: 0.8708 - val_loss: 0.4248 - val_accuracy: 0.8444\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.5839 - accuracy: 0.8726 - val_loss: 0.4263 - val_accuracy: 0.8508\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.3039 - accuracy: 0.8778 - val_loss: 0.3978 - val_accuracy: 0.8598\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.3088 - accuracy: 0.8782 - val_loss: 0.4240 - val_accuracy: 0.8532\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.2462 - accuracy: 0.8799 - val_loss: 0.4325 - val_accuracy: 0.8448\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.0720 - accuracy: 0.8837 - val_loss: 0.4048 - val_accuracy: 0.8557\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 3.9237 - accuracy: 0.8870 - val_loss: 0.4308 - val_accuracy: 0.8497\n",
      "Epoch 28/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 3.8046 - accuracy: 0.8886 - val_loss: 0.4264 - val_accuracy: 0.8533\n",
      "2975/2975 [==============================] - 18s 5ms/step\n",
      "372/372 [==============================] - 2s 6ms/step - loss: 0.4155 - accuracy: 0.8527\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 24ms/step - loss: 19.9571 - accuracy: 0.4337 - val_loss: 1.1861 - val_accuracy: 0.5978\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 13.0330 - accuracy: 0.6458 - val_loss: 0.8463 - val_accuracy: 0.6898\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 10.7153 - accuracy: 0.7094 - val_loss: 0.6989 - val_accuracy: 0.7526\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744/744 [==============================] - 16s 21ms/step - loss: 9.2642 - accuracy: 0.7523 - val_loss: 0.6255 - val_accuracy: 0.7732\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 8.3788 - accuracy: 0.7775 - val_loss: 0.5627 - val_accuracy: 0.7940\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.7303 - accuracy: 0.7973 - val_loss: 0.5144 - val_accuracy: 0.8116\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.2492 - accuracy: 0.8101 - val_loss: 0.5038 - val_accuracy: 0.8143\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.9341 - accuracy: 0.8187 - val_loss: 0.4697 - val_accuracy: 0.8319\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.6828 - accuracy: 0.8244 - val_loss: 0.4676 - val_accuracy: 0.8305\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.4520 - accuracy: 0.8305 - val_loss: 0.4281 - val_accuracy: 0.8415\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.1738 - accuracy: 0.8360 - val_loss: 0.4546 - val_accuracy: 0.8326\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.0034 - accuracy: 0.8396 - val_loss: 0.4512 - val_accuracy: 0.8346\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.8278 - accuracy: 0.8449 - val_loss: 0.4491 - val_accuracy: 0.8362\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.6426 - accuracy: 0.8509 - val_loss: 0.4196 - val_accuracy: 0.8474\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.4634 - accuracy: 0.8534 - val_loss: 0.4302 - val_accuracy: 0.8426\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.3228 - accuracy: 0.8558 - val_loss: 0.4103 - val_accuracy: 0.8470\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.1682 - accuracy: 0.8599 - val_loss: 0.4111 - val_accuracy: 0.8503\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.1053 - accuracy: 0.8600 - val_loss: 0.4153 - val_accuracy: 0.8495\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.9018 - accuracy: 0.8654 - val_loss: 0.4000 - val_accuracy: 0.8517\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.8136 - accuracy: 0.8669 - val_loss: 0.4178 - val_accuracy: 0.8499\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.6391 - accuracy: 0.8704 - val_loss: 0.4174 - val_accuracy: 0.8479\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.5960 - accuracy: 0.8707 - val_loss: 0.4029 - val_accuracy: 0.8537\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.3899 - accuracy: 0.8762 - val_loss: 0.4253 - val_accuracy: 0.8528\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.3209 - accuracy: 0.8775 - val_loss: 0.4256 - val_accuracy: 0.8488\n",
      "2975/2975 [==============================] - 18s 5ms/step\n",
      "372/372 [==============================] - 2s 6ms/step - loss: 0.4207 - accuracy: 0.8454\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 25s 25ms/step - loss: 19.7898 - accuracy: 0.4360 - val_loss: 1.2644 - val_accuracy: 0.5388\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 13.2719 - accuracy: 0.6352 - val_loss: 0.8739 - val_accuracy: 0.6895\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 10.9822 - accuracy: 0.6965 - val_loss: 0.7518 - val_accuracy: 0.7266\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 9.5888 - accuracy: 0.7412 - val_loss: 0.6179 - val_accuracy: 0.7788\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.6729 - accuracy: 0.7682 - val_loss: 0.5759 - val_accuracy: 0.7916\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.0521 - accuracy: 0.7872 - val_loss: 0.5385 - val_accuracy: 0.8016\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.5548 - accuracy: 0.8007 - val_loss: 0.5271 - val_accuracy: 0.8109\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.1443 - accuracy: 0.8113 - val_loss: 0.5729 - val_accuracy: 0.7876\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.8327 - accuracy: 0.8196 - val_loss: 0.5051 - val_accuracy: 0.8112\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.5931 - accuracy: 0.8258 - val_loss: 0.4758 - val_accuracy: 0.8267\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.3471 - accuracy: 0.8320 - val_loss: 0.5020 - val_accuracy: 0.8165\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.1243 - accuracy: 0.8369 - val_loss: 0.4467 - val_accuracy: 0.8363\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.0179 - accuracy: 0.8403 - val_loss: 0.4743 - val_accuracy: 0.8221\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.7656 - accuracy: 0.8448 - val_loss: 0.4666 - val_accuracy: 0.8301\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5959 - accuracy: 0.8492 - val_loss: 0.4529 - val_accuracy: 0.8351\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3464 - accuracy: 0.8550 - val_loss: 0.4424 - val_accuracy: 0.8393\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.2744 - accuracy: 0.8560 - val_loss: 0.4251 - val_accuracy: 0.8523\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.1535 - accuracy: 0.8586 - val_loss: 0.4639 - val_accuracy: 0.8327\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.9482 - accuracy: 0.8635 - val_loss: 0.3986 - val_accuracy: 0.8548\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.8534 - accuracy: 0.8654 - val_loss: 0.4344 - val_accuracy: 0.8422\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.7394 - accuracy: 0.8675 - val_loss: 0.4023 - val_accuracy: 0.8567\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.5502 - accuracy: 0.8731 - val_loss: 0.4487 - val_accuracy: 0.8385\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.4945 - accuracy: 0.8730 - val_loss: 0.4176 - val_accuracy: 0.8501\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.3448 - accuracy: 0.8766 - val_loss: 0.4149 - val_accuracy: 0.8503\n",
      "2975/2975 [==============================] - 18s 5ms/step\n",
      "372/372 [==============================] - 2s 6ms/step - loss: 0.4160 - accuracy: 0.8468\n",
      "372/372 [==============================] - 2s 6ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 24ms/step - loss: 19.5625 - accuracy: 0.4410 - val_loss: 1.2009 - val_accuracy: 0.5835\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 13.2005 - accuracy: 0.6385 - val_loss: 0.9014 - val_accuracy: 0.6804\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 10.6565 - accuracy: 0.7076 - val_loss: 0.6801 - val_accuracy: 0.7509\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.3253 - accuracy: 0.7485 - val_loss: 0.7221 - val_accuracy: 0.7325\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 8.4989 - accuracy: 0.7736 - val_loss: 0.6021 - val_accuracy: 0.7861\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.8570 - accuracy: 0.7914 - val_loss: 0.5250 - val_accuracy: 0.8124\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.4082 - accuracy: 0.8057 - val_loss: 0.4998 - val_accuracy: 0.8196\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.9610 - accuracy: 0.8167 - val_loss: 0.5007 - val_accuracy: 0.8196\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.7365 - accuracy: 0.8240 - val_loss: 0.4947 - val_accuracy: 0.8219\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.4579 - accuracy: 0.8302 - val_loss: 0.4605 - val_accuracy: 0.8326\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.2130 - accuracy: 0.8349 - val_loss: 0.4623 - val_accuracy: 0.8320\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.0257 - accuracy: 0.8396 - val_loss: 0.4364 - val_accuracy: 0.8402\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.8056 - accuracy: 0.8443 - val_loss: 0.4856 - val_accuracy: 0.8208\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.6926 - accuracy: 0.8461 - val_loss: 0.4427 - val_accuracy: 0.8364\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.4952 - accuracy: 0.8508 - val_loss: 0.4610 - val_accuracy: 0.8321\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.3663 - accuracy: 0.8540 - val_loss: 0.4276 - val_accuracy: 0.8459\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.1471 - accuracy: 0.8589 - val_loss: 0.4467 - val_accuracy: 0.8346\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.0335 - accuracy: 0.8601 - val_loss: 0.4673 - val_accuracy: 0.8334\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.9311 - accuracy: 0.8631 - val_loss: 0.4079 - val_accuracy: 0.8555\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.7541 - accuracy: 0.8666 - val_loss: 0.4283 - val_accuracy: 0.8440\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.6830 - accuracy: 0.8673 - val_loss: 0.4103 - val_accuracy: 0.8506\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.5412 - accuracy: 0.8713 - val_loss: 0.4358 - val_accuracy: 0.8420\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.4857 - accuracy: 0.8731 - val_loss: 0.4332 - val_accuracy: 0.8439\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.3088 - accuracy: 0.8759 - val_loss: 0.4305 - val_accuracy: 0.8417\n",
      "2975/2975 [==============================] - 18s 5ms/step\n",
      "372/372 [==============================] - 2s 6ms/step - loss: 0.4370 - accuracy: 0.8441\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 25s 24ms/step - loss: 19.9514 - accuracy: 0.4311 - val_loss: 1.1382 - val_accuracy: 0.6089\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 13.1269 - accuracy: 0.6375 - val_loss: 0.8368 - val_accuracy: 0.6974\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.7761 - accuracy: 0.7050 - val_loss: 0.7592 - val_accuracy: 0.7210\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.4207 - accuracy: 0.7444 - val_loss: 0.6789 - val_accuracy: 0.7518\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 8.5867 - accuracy: 0.7708 - val_loss: 0.5704 - val_accuracy: 0.7947\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.9453 - accuracy: 0.7900 - val_loss: 0.6167 - val_accuracy: 0.7792\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.4914 - accuracy: 0.8025 - val_loss: 0.5004 - val_accuracy: 0.8171\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.1254 - accuracy: 0.8133 - val_loss: 0.5075 - val_accuracy: 0.8188\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.8145 - accuracy: 0.8206 - val_loss: 0.4981 - val_accuracy: 0.8164\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.5029 - accuracy: 0.8295 - val_loss: 0.4556 - val_accuracy: 0.8339\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.3624 - accuracy: 0.8338 - val_loss: 0.4713 - val_accuracy: 0.8290\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.0821 - accuracy: 0.8388 - val_loss: 0.4585 - val_accuracy: 0.8296\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.9221 - accuracy: 0.8437 - val_loss: 0.5284 - val_accuracy: 0.8078\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.7650 - accuracy: 0.8475 - val_loss: 0.4196 - val_accuracy: 0.8455\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.5329 - accuracy: 0.8515 - val_loss: 0.4087 - val_accuracy: 0.8529\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.3803 - accuracy: 0.8552 - val_loss: 0.4287 - val_accuracy: 0.8421\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.2865 - accuracy: 0.8560 - val_loss: 0.4383 - val_accuracy: 0.8363\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.1429 - accuracy: 0.8586 - val_loss: 0.4511 - val_accuracy: 0.8359\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.0241 - accuracy: 0.8638 - val_loss: 0.4696 - val_accuracy: 0.8301\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.9353 - accuracy: 0.8643 - val_loss: 0.4324 - val_accuracy: 0.8431\n",
      "2975/2975 [==============================] - 18s 5ms/step\n",
      "372/372 [==============================] - 2s 6ms/step - loss: 0.4364 - accuracy: 0.8446\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 25s 25ms/step - loss: 19.8408 - accuracy: 0.4376 - val_loss: 1.2001 - val_accuracy: 0.5851\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 13.2272 - accuracy: 0.6354 - val_loss: 0.9045 - val_accuracy: 0.6680\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 10.7135 - accuracy: 0.7080 - val_loss: 0.7146 - val_accuracy: 0.7368\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.3879 - accuracy: 0.7490 - val_loss: 0.8084 - val_accuracy: 0.6998\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 8.4839 - accuracy: 0.7739 - val_loss: 0.5594 - val_accuracy: 0.7943\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.8365 - accuracy: 0.7929 - val_loss: 0.5273 - val_accuracy: 0.8111\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.4746 - accuracy: 0.8036 - val_loss: 0.5697 - val_accuracy: 0.7879\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.0481 - accuracy: 0.8149 - val_loss: 0.4645 - val_accuracy: 0.8322\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.7849 - accuracy: 0.8225 - val_loss: 0.4588 - val_accuracy: 0.8327\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.4338 - accuracy: 0.8307 - val_loss: 0.5009 - val_accuracy: 0.8217\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.2410 - accuracy: 0.8350 - val_loss: 0.4399 - val_accuracy: 0.8422\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.1196 - accuracy: 0.8397 - val_loss: 0.4206 - val_accuracy: 0.8491\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.8540 - accuracy: 0.8452 - val_loss: 0.4607 - val_accuracy: 0.8326\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.7168 - accuracy: 0.8473 - val_loss: 0.5080 - val_accuracy: 0.8207\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.5143 - accuracy: 0.8522 - val_loss: 0.4459 - val_accuracy: 0.8390\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.3710 - accuracy: 0.8554 - val_loss: 0.4759 - val_accuracy: 0.8231\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.1685 - accuracy: 0.8591 - val_loss: 0.4498 - val_accuracy: 0.8416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975/2975 [==============================] - 18s 5ms/step\n",
      "372/372 [==============================] - 2s 6ms/step - loss: 0.4397 - accuracy: 0.8422\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 24ms/step - loss: 19.7545 - accuracy: 0.4438 - val_loss: 1.1643 - val_accuracy: 0.5862\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 13.2692 - accuracy: 0.6351 - val_loss: 0.9141 - val_accuracy: 0.6610\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 10.8268 - accuracy: 0.7021 - val_loss: 0.7574 - val_accuracy: 0.7196\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 9.5114 - accuracy: 0.7414 - val_loss: 0.6142 - val_accuracy: 0.7753\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 8.6300 - accuracy: 0.7698 - val_loss: 0.5945 - val_accuracy: 0.7848\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 8.0261 - accuracy: 0.7874 - val_loss: 0.5354 - val_accuracy: 0.8039\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.5110 - accuracy: 0.8019 - val_loss: 0.5434 - val_accuracy: 0.8055\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.1359 - accuracy: 0.8126 - val_loss: 0.5043 - val_accuracy: 0.8152\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.9158 - accuracy: 0.8176 - val_loss: 0.4660 - val_accuracy: 0.8302\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.5903 - accuracy: 0.8256 - val_loss: 0.4803 - val_accuracy: 0.8279\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.2801 - accuracy: 0.8352 - val_loss: 0.4841 - val_accuracy: 0.8224\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.0814 - accuracy: 0.8389 - val_loss: 0.4614 - val_accuracy: 0.8322\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.9145 - accuracy: 0.8431 - val_loss: 0.4572 - val_accuracy: 0.8365\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.7426 - accuracy: 0.8460 - val_loss: 0.4484 - val_accuracy: 0.8344\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.5211 - accuracy: 0.8517 - val_loss: 0.4343 - val_accuracy: 0.8395\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.4077 - accuracy: 0.8533 - val_loss: 0.4284 - val_accuracy: 0.8479\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.1735 - accuracy: 0.8600 - val_loss: 0.4381 - val_accuracy: 0.8398\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.1403 - accuracy: 0.8588 - val_loss: 0.4146 - val_accuracy: 0.8508\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.9383 - accuracy: 0.8639 - val_loss: 0.4195 - val_accuracy: 0.8454\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.7325 - accuracy: 0.8684 - val_loss: 0.4497 - val_accuracy: 0.8415\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.7080 - accuracy: 0.8687 - val_loss: 0.4630 - val_accuracy: 0.8327\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.5842 - accuracy: 0.8722 - val_loss: 0.4185 - val_accuracy: 0.8512\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.4768 - accuracy: 0.8741 - val_loss: 0.4088 - val_accuracy: 0.8525\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.2362 - accuracy: 0.8788 - val_loss: 0.4501 - val_accuracy: 0.8398\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.2099 - accuracy: 0.8786 - val_loss: 0.4082 - val_accuracy: 0.8544\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.0467 - accuracy: 0.8835 - val_loss: 0.4051 - val_accuracy: 0.8575\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.0338 - accuracy: 0.8831 - val_loss: 0.4264 - val_accuracy: 0.8538\n",
      "Epoch 28/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 3.8410 - accuracy: 0.8881 - val_loss: 0.4302 - val_accuracy: 0.8490\n",
      "Epoch 29/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 3.7029 - accuracy: 0.8906 - val_loss: 0.4382 - val_accuracy: 0.8554\n",
      "Epoch 30/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 3.6206 - accuracy: 0.8920 - val_loss: 0.4201 - val_accuracy: 0.8585\n",
      "Epoch 31/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 3.4073 - accuracy: 0.8969 - val_loss: 0.4134 - val_accuracy: 0.8626\n",
      "2975/2975 [==============================] - 17s 5ms/step\n",
      "372/372 [==============================] - 2s 6ms/step - loss: 0.4265 - accuracy: 0.8503\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 25s 24ms/step - loss: 19.8587 - accuracy: 0.4319 - val_loss: 1.1934 - val_accuracy: 0.5872\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 13.0448 - accuracy: 0.6410 - val_loss: 0.9347 - val_accuracy: 0.6491\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 10.5786 - accuracy: 0.7108 - val_loss: 0.7005 - val_accuracy: 0.7462\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 9.2426 - accuracy: 0.7526 - val_loss: 0.6480 - val_accuracy: 0.7633\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 8.4677 - accuracy: 0.7762 - val_loss: 0.5854 - val_accuracy: 0.7865\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.9272 - accuracy: 0.7900 - val_loss: 0.5371 - val_accuracy: 0.8046\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.4519 - accuracy: 0.8035 - val_loss: 0.5205 - val_accuracy: 0.8077\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.0395 - accuracy: 0.8148 - val_loss: 0.5275 - val_accuracy: 0.8006\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.8021 - accuracy: 0.8215 - val_loss: 0.4868 - val_accuracy: 0.8284\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.4620 - accuracy: 0.8287 - val_loss: 0.5328 - val_accuracy: 0.8068\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.2725 - accuracy: 0.8338 - val_loss: 0.5034 - val_accuracy: 0.8101\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.0069 - accuracy: 0.8388 - val_loss: 0.4578 - val_accuracy: 0.8338\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.8447 - accuracy: 0.8438 - val_loss: 0.4418 - val_accuracy: 0.8393\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.6469 - accuracy: 0.8488 - val_loss: 0.4302 - val_accuracy: 0.8459\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.4956 - accuracy: 0.8498 - val_loss: 0.4275 - val_accuracy: 0.8445\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3335 - accuracy: 0.8544 - val_loss: 0.4164 - val_accuracy: 0.8500\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.2446 - accuracy: 0.8550 - val_loss: 0.4128 - val_accuracy: 0.8494\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.0763 - accuracy: 0.8602 - val_loss: 0.4922 - val_accuracy: 0.8265\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.9295 - accuracy: 0.8619 - val_loss: 0.4149 - val_accuracy: 0.8502\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.7468 - accuracy: 0.8671 - val_loss: 0.4112 - val_accuracy: 0.8501\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.6694 - accuracy: 0.8684 - val_loss: 0.4122 - val_accuracy: 0.8526\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.5291 - accuracy: 0.8718 - val_loss: 0.4197 - val_accuracy: 0.8527\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744/744 [==============================] - 16s 21ms/step - loss: 4.4828 - accuracy: 0.8717 - val_loss: 0.4212 - val_accuracy: 0.8447\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.2168 - accuracy: 0.8779 - val_loss: 0.4164 - val_accuracy: 0.8536\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.2037 - accuracy: 0.8775 - val_loss: 0.3907 - val_accuracy: 0.8628\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.0241 - accuracy: 0.8821 - val_loss: 0.4011 - val_accuracy: 0.8564\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 3.9316 - accuracy: 0.8842 - val_loss: 0.4030 - val_accuracy: 0.8578\n",
      "Epoch 28/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 3.9395 - accuracy: 0.8842 - val_loss: 0.4294 - val_accuracy: 0.8516\n",
      "Epoch 29/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 3.6933 - accuracy: 0.8890 - val_loss: 0.4096 - val_accuracy: 0.8584\n",
      "Epoch 30/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 3.6146 - accuracy: 0.8907 - val_loss: 0.4090 - val_accuracy: 0.8568\n",
      "2975/2975 [==============================] - 18s 5ms/step\n",
      "372/372 [==============================] - 2s 6ms/step - loss: 0.4145 - accuracy: 0.8567\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 24ms/step - loss: 19.9575 - accuracy: 0.4278 - val_loss: 1.1450 - val_accuracy: 0.6031\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 13.2769 - accuracy: 0.6336 - val_loss: 0.9469 - val_accuracy: 0.6505\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 10.7371 - accuracy: 0.7055 - val_loss: 0.7195 - val_accuracy: 0.7357\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 9.2732 - accuracy: 0.7501 - val_loss: 0.5754 - val_accuracy: 0.7925\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 8.3492 - accuracy: 0.7800 - val_loss: 0.5480 - val_accuracy: 0.7984\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.6964 - accuracy: 0.7982 - val_loss: 0.5897 - val_accuracy: 0.7879\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.2037 - accuracy: 0.8110 - val_loss: 0.5244 - val_accuracy: 0.8072\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.9774 - accuracy: 0.8168 - val_loss: 0.4841 - val_accuracy: 0.8221\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.6601 - accuracy: 0.8259 - val_loss: 0.4613 - val_accuracy: 0.8322\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.3643 - accuracy: 0.8333 - val_loss: 0.4404 - val_accuracy: 0.8381\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.0811 - accuracy: 0.8398 - val_loss: 0.4951 - val_accuracy: 0.8191\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.9089 - accuracy: 0.8437 - val_loss: 0.4279 - val_accuracy: 0.8436\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.7230 - accuracy: 0.8478 - val_loss: 0.4386 - val_accuracy: 0.8404\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.6018 - accuracy: 0.8517 - val_loss: 0.5124 - val_accuracy: 0.8151\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.3553 - accuracy: 0.8572 - val_loss: 0.4088 - val_accuracy: 0.8527\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.2328 - accuracy: 0.8589 - val_loss: 0.4136 - val_accuracy: 0.8478\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.1188 - accuracy: 0.8604 - val_loss: 0.4003 - val_accuracy: 0.8526\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.9639 - accuracy: 0.8656 - val_loss: 0.3937 - val_accuracy: 0.8551\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.8278 - accuracy: 0.8668 - val_loss: 0.4085 - val_accuracy: 0.8506\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.6643 - accuracy: 0.8705 - val_loss: 0.4211 - val_accuracy: 0.8527\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.5542 - accuracy: 0.8737 - val_loss: 0.4001 - val_accuracy: 0.8528\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.3987 - accuracy: 0.8762 - val_loss: 0.4293 - val_accuracy: 0.8506\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.3252 - accuracy: 0.8776 - val_loss: 0.3886 - val_accuracy: 0.8643\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.1605 - accuracy: 0.8801 - val_loss: 0.4056 - val_accuracy: 0.8570\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.1127 - accuracy: 0.8807 - val_loss: 0.4181 - val_accuracy: 0.8524\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 3.9624 - accuracy: 0.8852 - val_loss: 0.4000 - val_accuracy: 0.8566\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 3.9032 - accuracy: 0.8857 - val_loss: 0.4170 - val_accuracy: 0.8523\n",
      "Epoch 28/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 3.7307 - accuracy: 0.8894 - val_loss: 0.4078 - val_accuracy: 0.8561\n",
      "2975/2975 [==============================] - 17s 5ms/step\n",
      "372/372 [==============================] - 2s 6ms/step - loss: 0.4136 - accuracy: 0.8556\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 25s 24ms/step - loss: 19.7731 - accuracy: 0.4314 - val_loss: 1.2060 - val_accuracy: 0.5919\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 13.4064 - accuracy: 0.6313 - val_loss: 0.8938 - val_accuracy: 0.6809\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.0791 - accuracy: 0.6925 - val_loss: 0.7678 - val_accuracy: 0.7196\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.5471 - accuracy: 0.7426 - val_loss: 0.6809 - val_accuracy: 0.7467\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.6528 - accuracy: 0.7694 - val_loss: 0.5828 - val_accuracy: 0.7889\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 7.9308 - accuracy: 0.7912 - val_loss: 0.5390 - val_accuracy: 0.8072\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.3726 - accuracy: 0.8073 - val_loss: 0.5506 - val_accuracy: 0.8022\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.0050 - accuracy: 0.8164 - val_loss: 0.4631 - val_accuracy: 0.8285\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.7502 - accuracy: 0.8225 - val_loss: 0.5159 - val_accuracy: 0.8138\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.5605 - accuracy: 0.8279 - val_loss: 0.4293 - val_accuracy: 0.8425\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.1783 - accuracy: 0.8360 - val_loss: 0.5116 - val_accuracy: 0.8186\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.0053 - accuracy: 0.8411 - val_loss: 0.4491 - val_accuracy: 0.8363\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.8366 - accuracy: 0.8448 - val_loss: 0.4166 - val_accuracy: 0.8469\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.5562 - accuracy: 0.8521 - val_loss: 0.4483 - val_accuracy: 0.8322\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.4954 - accuracy: 0.8518 - val_loss: 0.4154 - val_accuracy: 0.8476\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3834 - accuracy: 0.8543 - val_loss: 0.4413 - val_accuracy: 0.8352\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.1528 - accuracy: 0.8597 - val_loss: 0.4078 - val_accuracy: 0.8485\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.0181 - accuracy: 0.8630 - val_loss: 0.4049 - val_accuracy: 0.8506\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.8786 - accuracy: 0.8663 - val_loss: 0.4101 - val_accuracy: 0.8528\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.7584 - accuracy: 0.8694 - val_loss: 0.4200 - val_accuracy: 0.8459\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.6111 - accuracy: 0.8714 - val_loss: 0.4189 - val_accuracy: 0.8475\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.4446 - accuracy: 0.8751 - val_loss: 0.4061 - val_accuracy: 0.8573\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.3350 - accuracy: 0.8773 - val_loss: 0.3991 - val_accuracy: 0.8559\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.2774 - accuracy: 0.8776 - val_loss: 0.4239 - val_accuracy: 0.8422\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.0592 - accuracy: 0.8828 - val_loss: 0.4173 - val_accuracy: 0.8564\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 3.9409 - accuracy: 0.8848 - val_loss: 0.4199 - val_accuracy: 0.8538\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 3.9424 - accuracy: 0.8843 - val_loss: 0.4885 - val_accuracy: 0.8295\n",
      "Epoch 28/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 3.8204 - accuracy: 0.8881 - val_loss: 0.4346 - val_accuracy: 0.8441\n",
      "2975/2975 [==============================] - 17s 5ms/step\n",
      "372/372 [==============================] - 2s 6ms/step - loss: 0.4256 - accuracy: 0.8485\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 23s 24ms/step - loss: 19.6348 - accuracy: 0.4403 - val_loss: 1.2112 - val_accuracy: 0.5837\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 13.1459 - accuracy: 0.6367 - val_loss: 0.9189 - val_accuracy: 0.6689\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 10.6478 - accuracy: 0.7083 - val_loss: 0.6869 - val_accuracy: 0.7454\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 9.2103 - accuracy: 0.7527 - val_loss: 0.6353 - val_accuracy: 0.7700\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 8.4689 - accuracy: 0.7743 - val_loss: 0.6365 - val_accuracy: 0.7687\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.8401 - accuracy: 0.7924 - val_loss: 0.5178 - val_accuracy: 0.8118\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.3134 - accuracy: 0.8088 - val_loss: 0.5250 - val_accuracy: 0.8139\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.0105 - accuracy: 0.8147 - val_loss: 0.5179 - val_accuracy: 0.8098\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.6045 - accuracy: 0.8255 - val_loss: 0.4714 - val_accuracy: 0.8295\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.3856 - accuracy: 0.8302 - val_loss: 0.4581 - val_accuracy: 0.8357\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.2183 - accuracy: 0.8344 - val_loss: 0.4471 - val_accuracy: 0.8381\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.0065 - accuracy: 0.8394 - val_loss: 0.4343 - val_accuracy: 0.8417\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.8662 - accuracy: 0.8437 - val_loss: 0.5020 - val_accuracy: 0.8190\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.6078 - accuracy: 0.8483 - val_loss: 0.4113 - val_accuracy: 0.8487\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.4611 - accuracy: 0.8522 - val_loss: 0.4325 - val_accuracy: 0.8383\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.3825 - accuracy: 0.8532 - val_loss: 0.4561 - val_accuracy: 0.8327\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.1491 - accuracy: 0.8589 - val_loss: 0.4012 - val_accuracy: 0.8523\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.0107 - accuracy: 0.8613 - val_loss: 0.4301 - val_accuracy: 0.8417\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.8990 - accuracy: 0.8633 - val_loss: 0.4298 - val_accuracy: 0.8449\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.7100 - accuracy: 0.8677 - val_loss: 0.4532 - val_accuracy: 0.8314\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.6166 - accuracy: 0.8690 - val_loss: 0.4482 - val_accuracy: 0.8390\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.4807 - accuracy: 0.8733 - val_loss: 0.4256 - val_accuracy: 0.8458\n",
      "2975/2975 [==============================] - 17s 5ms/step\n",
      "372/372 [==============================] - 2s 6ms/step - loss: 0.4247 - accuracy: 0.8446\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 23s 24ms/step - loss: 19.9662 - accuracy: 0.4249 - val_loss: 1.2209 - val_accuracy: 0.5833\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 13.3473 - accuracy: 0.6341 - val_loss: 0.8979 - val_accuracy: 0.6662\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 10.8484 - accuracy: 0.7019 - val_loss: 0.7261 - val_accuracy: 0.7344\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 9.3305 - accuracy: 0.7471 - val_loss: 0.6038 - val_accuracy: 0.7798\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 8.4672 - accuracy: 0.7728 - val_loss: 0.6619 - val_accuracy: 0.7598\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.8228 - accuracy: 0.7928 - val_loss: 0.5457 - val_accuracy: 0.7977\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.3083 - accuracy: 0.8058 - val_loss: 0.5056 - val_accuracy: 0.8186\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 7.0458 - accuracy: 0.8147 - val_loss: 0.5036 - val_accuracy: 0.8160\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.6416 - accuracy: 0.8251 - val_loss: 0.4872 - val_accuracy: 0.8226\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.4129 - accuracy: 0.8314 - val_loss: 0.4593 - val_accuracy: 0.8321\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 6.2083 - accuracy: 0.8360 - val_loss: 0.4529 - val_accuracy: 0.8342\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.9546 - accuracy: 0.8415 - val_loss: 0.5100 - val_accuracy: 0.8137\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.8128 - accuracy: 0.8451 - val_loss: 0.4410 - val_accuracy: 0.8412\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.6205 - accuracy: 0.8493 - val_loss: 0.4192 - val_accuracy: 0.8462\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.3888 - accuracy: 0.8555 - val_loss: 0.4577 - val_accuracy: 0.8322\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.3424 - accuracy: 0.8567 - val_loss: 0.4544 - val_accuracy: 0.8331\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.1273 - accuracy: 0.8607 - val_loss: 0.4197 - val_accuracy: 0.8456\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.0248 - accuracy: 0.8637 - val_loss: 0.4056 - val_accuracy: 0.8541\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.8405 - accuracy: 0.8674 - val_loss: 0.4409 - val_accuracy: 0.8411\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.7332 - accuracy: 0.8695 - val_loss: 0.3821 - val_accuracy: 0.8638\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744/744 [==============================] - 16s 22ms/step - loss: 4.6574 - accuracy: 0.8704 - val_loss: 0.3929 - val_accuracy: 0.8602\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.5091 - accuracy: 0.8734 - val_loss: 0.3955 - val_accuracy: 0.8592\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.3322 - accuracy: 0.8784 - val_loss: 0.4123 - val_accuracy: 0.8558\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.2345 - accuracy: 0.8797 - val_loss: 0.4153 - val_accuracy: 0.8544\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.1289 - accuracy: 0.8807 - val_loss: 0.4257 - val_accuracy: 0.8494\n",
      "2975/2975 [==============================] - 19s 5ms/step\n",
      "372/372 [==============================] - 2s 6ms/step - loss: 0.4002 - accuracy: 0.8596\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 24ms/step - loss: 19.3439 - accuracy: 0.4536 - val_loss: 1.1756 - val_accuracy: 0.5979\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 13.0929 - accuracy: 0.6398 - val_loss: 0.8819 - val_accuracy: 0.6884\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 10.6506 - accuracy: 0.7087 - val_loss: 0.7156 - val_accuracy: 0.7380\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.3622 - accuracy: 0.7484 - val_loss: 0.6110 - val_accuracy: 0.7763\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.5421 - accuracy: 0.7722 - val_loss: 0.5441 - val_accuracy: 0.8011\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.8326 - accuracy: 0.7926 - val_loss: 0.5744 - val_accuracy: 0.7943\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.3765 - accuracy: 0.8067 - val_loss: 0.5224 - val_accuracy: 0.8097\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.9426 - accuracy: 0.8163 - val_loss: 0.4872 - val_accuracy: 0.8238\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.7552 - accuracy: 0.8221 - val_loss: 0.5145 - val_accuracy: 0.8083\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.3444 - accuracy: 0.8318 - val_loss: 0.4958 - val_accuracy: 0.8237\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.1704 - accuracy: 0.8360 - val_loss: 0.5567 - val_accuracy: 0.7969\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.0192 - accuracy: 0.8401 - val_loss: 0.4874 - val_accuracy: 0.8184\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.7426 - accuracy: 0.8451 - val_loss: 0.4323 - val_accuracy: 0.8380\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.5952 - accuracy: 0.8499 - val_loss: 0.4610 - val_accuracy: 0.8339\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.4811 - accuracy: 0.8525 - val_loss: 0.4149 - val_accuracy: 0.8510\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.2788 - accuracy: 0.8576 - val_loss: 0.4268 - val_accuracy: 0.8428\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.1077 - accuracy: 0.8596 - val_loss: 0.4176 - val_accuracy: 0.8467\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 5.0338 - accuracy: 0.8622 - val_loss: 0.4543 - val_accuracy: 0.8391\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.8442 - accuracy: 0.8661 - val_loss: 0.3976 - val_accuracy: 0.8575\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.7052 - accuracy: 0.8696 - val_loss: 0.4071 - val_accuracy: 0.8526\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.6143 - accuracy: 0.8711 - val_loss: 0.4047 - val_accuracy: 0.8536\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.4498 - accuracy: 0.8740 - val_loss: 0.4203 - val_accuracy: 0.8474\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 21ms/step - loss: 4.3355 - accuracy: 0.8766 - val_loss: 0.4568 - val_accuracy: 0.8367\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.1858 - accuracy: 0.8792 - val_loss: 0.4471 - val_accuracy: 0.8426\n",
      "2975/2975 [==============================] - 17s 5ms/step\n",
      "372/372 [==============================] - 2s 6ms/step - loss: 0.4085 - accuracy: 0.8533\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "for i in range(110, 260, 10):\n",
    "    if (i in szs or i in done):\n",
    "        continue\n",
    "    for _ in range(1):\n",
    "        model = train_model(i, True)\n",
    "        latent_model = Model(inputs=[model.get_layer('lc').input, model.get_layer('host').input], outputs=model.get_layer('latent').output)\n",
    "        train_pred = latent_model.predict([X_train, host_gal_train])\n",
    "\n",
    "        cls_perf.append(model.evaluate([X_test, host_gal_test], y_test))\n",
    "\n",
    "        detector = mcif(n_estimators=200)\n",
    "        detector.train(train_pred, y_train)\n",
    "\n",
    "        test_latent = (latent_model.predict([X_test, host_gal_test]))\n",
    "        test_pred = detector.score(test_latent)\n",
    "\n",
    "        anom_pred = detector.score((latent_model.predict([x_data_anom, host_gal_anom])))\n",
    "\n",
    "\n",
    "        rec.append(plot_recall(test_pred, anom_pred, ret=True))\n",
    "        done.append(i)\n",
    "\n",
    "        save(f'Latent{i}', model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372/372 [==============================] - 5s 6ms/step - loss: 0.4426 - accuracy: 0.8449\n",
      "2975/2975 [==============================] - 17s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "10 (33.9, 3.2264531609803355) [0.4426381289958954, 0.8449319005012512]\n"
     ]
    }
   ],
   "source": [
    "from astromcad.astromcad import *\n",
    "\n",
    "# corr = []\n",
    "\n",
    "# sz = []\n",
    "# recalls = []\n",
    "# accuracy = []\n",
    "\n",
    "for i in range(10, 11, 10):\n",
    "    model = load(f'models/Latent{i}')\n",
    "    latent_model = Model(inputs=[model.get_layer('lc').input, model.get_layer('host').input], outputs=model.get_layer('latent').output)\n",
    "    \n",
    "    eval = model.evaluate([X_test, host_gal_test], y_test)\n",
    "#     aurocs = get_auroc(test_pred, single_test)\n",
    "    \n",
    "    \n",
    "    train_pred = latent_model.predict([X_train, host_gal_train])\n",
    "#     df = pd.DataFrame(train_pred)\n",
    "#     corr.append(np.sum((df.corr() > 0.7)))\n",
    "#     print(corr[-1])\n",
    "    \n",
    "    detector = mcif(n_estimators=200)\n",
    "    detector.train(train_pred, y_train)\n",
    "    \n",
    "    test_latent = (latent_model.predict([X_test, host_gal_test]))\n",
    "    test_pred = detector.score(test_latent)\n",
    "    anom_pred = detector.score((latent_model.predict([x_data_anom, host_gal_anom])))\n",
    "    \n",
    "    \n",
    "    rec = plot_recall(test_pred, anom_pred, ret=True)\n",
    "  \n",
    "    recalls.append(rec)\n",
    "    sz.append(i)\n",
    "    accuracy.append(eval)\n",
    "    print(i, rec, eval)\n",
    "    #     save(f'models/LatentUpdated{i}', model)\n",
    "#     print(i, np.mean(model.aurocs), model.rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveplot(savepath):\n",
    "    if (savepath):\n",
    "        if (\"UMAP\" not in savepath):\n",
    "            plt.savefig(savepath + '.pdf', bbox_inches='tight')\n",
    "        else:\n",
    "            plt.savefig(savepath + '.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_data_anom)):\n",
    "    d[i] = file_to_class[y_data_anom[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "host_gal_train = np.array(host_gal_train)\n",
    "x_data_anom = np.array(x_data_anom)\n",
    "host_gal_anom = np.array(host_gal_anom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mcif:\n",
    "    def __init__(self, n_estimators = 400):\n",
    "        self.n_estimators=n_estimators\n",
    "\n",
    "    def train(self, x_data, labels):\n",
    "        self.classes = np.unique(labels, axis=0)\n",
    "        self.iforests = [IsolationForest(n_estimators=self.n_estimators) for i in self.classes]\n",
    "        self.weights = []\n",
    "        assert(len(labels) == len(x_data))\n",
    "        labels=np.array(labels)\n",
    "        for ind, cls in enumerate(self.classes):\n",
    "            here = []\n",
    "            for i in range(len(x_data)):\n",
    "#                 print(list(labels[i]))\n",
    "                if (list(cls) == list(labels[i])):\n",
    "                    here.append(x_data[i])\n",
    "                    \n",
    "            \n",
    "            self.weights.append(len(here) / len(x_data))\n",
    "            self.iforests[ind].fit(here)\n",
    "            \n",
    "\n",
    "    def score_discrete(self, data):\n",
    "        scores = [-det.decision_function(data) for det in self.iforests]\n",
    "\n",
    "        scores = np.array(scores)\n",
    "        scores = scores.T\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def score(self, data):\n",
    "        return [np.min(i) for i in self.score_discrete(data)]\n",
    "    \n",
    "    def score_mean(self, data):\n",
    "        return [np.mean(i) for i in self.score_discrete(data)]\n",
    "    \n",
    "    def score_weighted(self, data):\n",
    "        return [np.average(i, weights=self.weights) for i in self.score_discrete(data)]\n",
    "    \n",
    "    def score_wmin(self, data):\n",
    "        disc = self.score_discrete(data)\n",
    "        res = []\n",
    "        self.weights=np.array(self.weights)\n",
    "        for i in disc:\n",
    "            res.append(np.min(i / self.weights))\n",
    "            \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, roc_curve, roc_auc_score, auc\n",
    "def auroc(in_scores, out_scores, eps=1e-5):\n",
    "    \n",
    "    scores = np.concatenate((in_scores, out_scores), axis=0)\n",
    "    start = np.min(scores)\n",
    "    end = np.max(scores)   \n",
    "    gap = (end - start)/100\n",
    "\n",
    "    tprs = []\n",
    "    fprs = []\n",
    "    for delta in np.arange(end, start, -gap):\n",
    "        tpr = np.sum(np.sum(out_scores >= delta)) / (float(len(out_scores) + eps))\n",
    "        fpr = np.sum(np.sum(in_scores >= delta)) / (float(len(in_scores) + eps))\n",
    "        tprs.append(tpr)\n",
    "        fprs.append(fpr)\n",
    "    return auc(fprs, tprs), fprs, tprs\n",
    "\n",
    "aurocs = []\n",
    "rec = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 11:17:09.708298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1926] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31127 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:16:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 11:17:20.649157: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:467] Loaded cuDNN version 90000\n",
      "2024-05-19 11:17:21.174496: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_36/output/_23'\n",
      "2024-05-19 11:17:22.056671: I external/local_xla/xla/service/service.cc:168] XLA service 0x55c13287e0b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-19 11:17:22.056702: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-05-19 11:17:22.075557: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1716131842.219629   16661 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744/744 [==============================] - 28s 25ms/step - loss: 20.6295 - accuracy: 0.4145 - val_loss: 1.4297 - val_accuracy: 0.4950\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.4337 - accuracy: 0.5417 - val_loss: 1.1712 - val_accuracy: 0.5907\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.2045 - accuracy: 0.6073 - val_loss: 1.0315 - val_accuracy: 0.6358\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.6785 - accuracy: 0.6453 - val_loss: 0.9292 - val_accuracy: 0.6573\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.6176 - accuracy: 0.6752 - val_loss: 0.9044 - val_accuracy: 0.6706\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.5881 - accuracy: 0.7061 - val_loss: 0.7655 - val_accuracy: 0.7273\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.7417 - accuracy: 0.7312 - val_loss: 0.7414 - val_accuracy: 0.7284\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.1515 - accuracy: 0.7504 - val_loss: 0.7172 - val_accuracy: 0.7358\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.7588 - accuracy: 0.7619 - val_loss: 0.6293 - val_accuracy: 0.7673\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.1796 - accuracy: 0.7796 - val_loss: 0.5649 - val_accuracy: 0.7916\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.7941 - accuracy: 0.7894 - val_loss: 0.5638 - val_accuracy: 0.7948\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.5834 - accuracy: 0.7967 - val_loss: 0.5310 - val_accuracy: 0.8092\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.2228 - accuracy: 0.8071 - val_loss: 0.5694 - val_accuracy: 0.7895\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.9488 - accuracy: 0.8149 - val_loss: 0.5294 - val_accuracy: 0.8061\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.7185 - accuracy: 0.8208 - val_loss: 0.5116 - val_accuracy: 0.8091\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.4456 - accuracy: 0.8266 - val_loss: 0.4659 - val_accuracy: 0.8293\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.2791 - accuracy: 0.8314 - val_loss: 0.4840 - val_accuracy: 0.8222\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.1309 - accuracy: 0.8340 - val_loss: 0.4576 - val_accuracy: 0.8358\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.9249 - accuracy: 0.8393 - val_loss: 0.4263 - val_accuracy: 0.8436\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.7091 - accuracy: 0.8435 - val_loss: 0.4439 - val_accuracy: 0.8364\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.6074 - accuracy: 0.8462 - val_loss: 0.4474 - val_accuracy: 0.8361\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.4562 - accuracy: 0.8503 - val_loss: 0.4345 - val_accuracy: 0.8397\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.4015 - accuracy: 0.8512 - val_loss: 0.4631 - val_accuracy: 0.8297\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.2775 - accuracy: 0.8531 - val_loss: 0.4708 - val_accuracy: 0.8261\n",
      "2975/2975 [==============================] - 18s 6ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "140 0 (43.06, 2.8524375540929903) 0.9038176643426997\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 25ms/step - loss: 20.5725 - accuracy: 0.4125 - val_loss: 1.3894 - val_accuracy: 0.4993\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.1857 - accuracy: 0.5493 - val_loss: 1.1503 - val_accuracy: 0.5939\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.1119 - accuracy: 0.6074 - val_loss: 1.0084 - val_accuracy: 0.6451\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.5062 - accuracy: 0.6509 - val_loss: 0.8552 - val_accuracy: 0.6937\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.2912 - accuracy: 0.6861 - val_loss: 0.8115 - val_accuracy: 0.7057\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.2976 - accuracy: 0.7160 - val_loss: 0.7236 - val_accuracy: 0.7328\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.5796 - accuracy: 0.7361 - val_loss: 0.6840 - val_accuracy: 0.7516\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 8.9330 - accuracy: 0.7566 - val_loss: 0.6109 - val_accuracy: 0.7758\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.4582 - accuracy: 0.7718 - val_loss: 0.6133 - val_accuracy: 0.7748\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.0615 - accuracy: 0.7836 - val_loss: 0.5623 - val_accuracy: 0.7932\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.7009 - accuracy: 0.7936 - val_loss: 0.6062 - val_accuracy: 0.7797\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.3179 - accuracy: 0.8031 - val_loss: 0.5275 - val_accuracy: 0.8046\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.0266 - accuracy: 0.8122 - val_loss: 0.4846 - val_accuracy: 0.8215\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.8730 - accuracy: 0.8171 - val_loss: 0.5641 - val_accuracy: 0.7932\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.6193 - accuracy: 0.8234 - val_loss: 0.5041 - val_accuracy: 0.8132\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.4631 - accuracy: 0.8261 - val_loss: 0.4967 - val_accuracy: 0.8204\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.1831 - accuracy: 0.8328 - val_loss: 0.4618 - val_accuracy: 0.8320\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.0601 - accuracy: 0.8370 - val_loss: 0.4906 - val_accuracy: 0.8181\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.9633 - accuracy: 0.8381 - val_loss: 0.4663 - val_accuracy: 0.8322\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.7588 - accuracy: 0.8425 - val_loss: 0.4405 - val_accuracy: 0.8362\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.6211 - accuracy: 0.8462 - val_loss: 0.4298 - val_accuracy: 0.8422\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.4515 - accuracy: 0.8499 - val_loss: 0.4482 - val_accuracy: 0.8391\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3919 - accuracy: 0.8507 - val_loss: 0.4437 - val_accuracy: 0.8396\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.2312 - accuracy: 0.8544 - val_loss: 0.4228 - val_accuracy: 0.8482\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.0922 - accuracy: 0.8570 - val_loss: 0.4354 - val_accuracy: 0.8426\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.9506 - accuracy: 0.8613 - val_loss: 0.4344 - val_accuracy: 0.8448\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.8731 - accuracy: 0.8624 - val_loss: 0.4876 - val_accuracy: 0.8270\n",
      "Epoch 28/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.6947 - accuracy: 0.8667 - val_loss: 0.4229 - val_accuracy: 0.8473\n",
      "Epoch 29/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 4.6279 - accuracy: 0.8683 - val_loss: 0.4388 - val_accuracy: 0.8440\n",
      "2975/2975 [==============================] - 18s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "140 1 (43.06, 3.068615322910319) 0.9049073334280174\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 25ms/step - loss: 20.2083 - accuracy: 0.4235 - val_loss: 1.3858 - val_accuracy: 0.5240\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 15.8380 - accuracy: 0.5590 - val_loss: 1.0995 - val_accuracy: 0.6182\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 13.6377 - accuracy: 0.6229 - val_loss: 1.0294 - val_accuracy: 0.6284\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.2428 - accuracy: 0.6591 - val_loss: 0.8752 - val_accuracy: 0.6810\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.0883 - accuracy: 0.6928 - val_loss: 0.8756 - val_accuracy: 0.6690\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.2534 - accuracy: 0.7159 - val_loss: 0.8232 - val_accuracy: 0.6911\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.5920 - accuracy: 0.7375 - val_loss: 0.6689 - val_accuracy: 0.7532\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.0168 - accuracy: 0.7547 - val_loss: 0.6364 - val_accuracy: 0.7675\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.4976 - accuracy: 0.7707 - val_loss: 0.5694 - val_accuracy: 0.7916\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.1366 - accuracy: 0.7811 - val_loss: 0.6061 - val_accuracy: 0.7763\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.7446 - accuracy: 0.7936 - val_loss: 0.5324 - val_accuracy: 0.8036\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.4529 - accuracy: 0.8000 - val_loss: 0.5730 - val_accuracy: 0.7858\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.1068 - accuracy: 0.8091 - val_loss: 0.5360 - val_accuracy: 0.8068\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.8640 - accuracy: 0.8176 - val_loss: 0.5181 - val_accuracy: 0.8136\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.7105 - accuracy: 0.8193 - val_loss: 0.5165 - val_accuracy: 0.8112\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.4326 - accuracy: 0.8266 - val_loss: 0.4726 - val_accuracy: 0.8285\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.2944 - accuracy: 0.8317 - val_loss: 0.5158 - val_accuracy: 0.8127\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.0826 - accuracy: 0.8349 - val_loss: 0.4949 - val_accuracy: 0.8223\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.0195 - accuracy: 0.8356 - val_loss: 0.4222 - val_accuracy: 0.8456\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.8256 - accuracy: 0.8415 - val_loss: 0.4809 - val_accuracy: 0.8207\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.6287 - accuracy: 0.8456 - val_loss: 0.4416 - val_accuracy: 0.8422\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5378 - accuracy: 0.8474 - val_loss: 0.5029 - val_accuracy: 0.8232\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.4781 - accuracy: 0.8501 - val_loss: 0.4525 - val_accuracy: 0.8311\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.2648 - accuracy: 0.8544 - val_loss: 0.4355 - val_accuracy: 0.8444\n",
      "2975/2975 [==============================] - 18s 5ms/step\n",
      "372/372 [==============================] - 2s 6ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "140 2 (39.72, 3.3228903081504213) 0.8717328096761499\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 25s 25ms/step - loss: 20.5025 - accuracy: 0.4112 - val_loss: 1.4485 - val_accuracy: 0.4956\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.1500 - accuracy: 0.5479 - val_loss: 1.2130 - val_accuracy: 0.5825\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.0099 - accuracy: 0.6089 - val_loss: 1.0083 - val_accuracy: 0.6445\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 12.6400 - accuracy: 0.6444 - val_loss: 0.8807 - val_accuracy: 0.6836\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.4941 - accuracy: 0.6785 - val_loss: 0.9086 - val_accuracy: 0.6685\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.5649 - accuracy: 0.7055 - val_loss: 0.7504 - val_accuracy: 0.7291\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.7349 - accuracy: 0.7322 - val_loss: 0.7119 - val_accuracy: 0.7442\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.1341 - accuracy: 0.7515 - val_loss: 0.6224 - val_accuracy: 0.7727\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.5892 - accuracy: 0.7678 - val_loss: 0.5682 - val_accuracy: 0.7916\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.0741 - accuracy: 0.7832 - val_loss: 0.5946 - val_accuracy: 0.7779\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.7101 - accuracy: 0.7937 - val_loss: 0.5569 - val_accuracy: 0.8004\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 7.4385 - accuracy: 0.8011 - val_loss: 0.5537 - val_accuracy: 0.7958\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.0653 - accuracy: 0.8111 - val_loss: 0.5139 - val_accuracy: 0.8098\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.8864 - accuracy: 0.8167 - val_loss: 0.4839 - val_accuracy: 0.8246\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.7724 - accuracy: 0.8191 - val_loss: 0.4617 - val_accuracy: 0.8321\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.5074 - accuracy: 0.8250 - val_loss: 0.4546 - val_accuracy: 0.8340\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.2556 - accuracy: 0.8311 - val_loss: 0.4702 - val_accuracy: 0.8274\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.0714 - accuracy: 0.8360 - val_loss: 0.5011 - val_accuracy: 0.8182\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.9825 - accuracy: 0.8373 - val_loss: 0.4384 - val_accuracy: 0.8399\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.6988 - accuracy: 0.8445 - val_loss: 0.4649 - val_accuracy: 0.8339\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.7055 - accuracy: 0.8447 - val_loss: 0.4611 - val_accuracy: 0.8366\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5225 - accuracy: 0.8482 - val_loss: 0.4598 - val_accuracy: 0.8384\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3799 - accuracy: 0.8514 - val_loss: 0.4516 - val_accuracy: 0.8360\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.2012 - accuracy: 0.8553 - val_loss: 0.4546 - val_accuracy: 0.8327\n",
      "2975/2975 [==============================] - 18s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "150 0 (43.88, 2.970791140420343) 0.8964709880670552\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 25s 25ms/step - loss: 20.5489 - accuracy: 0.4089 - val_loss: 1.4308 - val_accuracy: 0.5086\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 16.3706 - accuracy: 0.5433 - val_loss: 1.1995 - val_accuracy: 0.5853\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.1230 - accuracy: 0.6087 - val_loss: 1.0039 - val_accuracy: 0.6384\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.4581 - accuracy: 0.6522 - val_loss: 0.8683 - val_accuracy: 0.6907\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.2562 - accuracy: 0.6872 - val_loss: 0.8447 - val_accuracy: 0.6942\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744/744 [==============================] - 16s 22ms/step - loss: 10.3562 - accuracy: 0.7131 - val_loss: 0.7589 - val_accuracy: 0.7233\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.6782 - accuracy: 0.7340 - val_loss: 0.6605 - val_accuracy: 0.7594\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.1152 - accuracy: 0.7508 - val_loss: 0.6711 - val_accuracy: 0.7579\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.5932 - accuracy: 0.7676 - val_loss: 0.5885 - val_accuracy: 0.7864\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.1268 - accuracy: 0.7824 - val_loss: 0.5670 - val_accuracy: 0.7930\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.7142 - accuracy: 0.7936 - val_loss: 0.5294 - val_accuracy: 0.8066\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.4562 - accuracy: 0.8002 - val_loss: 0.5384 - val_accuracy: 0.7995\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.1659 - accuracy: 0.8088 - val_loss: 0.5175 - val_accuracy: 0.8073\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.8985 - accuracy: 0.8151 - val_loss: 0.5208 - val_accuracy: 0.8091\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.7176 - accuracy: 0.8219 - val_loss: 0.4940 - val_accuracy: 0.8174\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.5314 - accuracy: 0.8249 - val_loss: 0.4613 - val_accuracy: 0.8310\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.2236 - accuracy: 0.8326 - val_loss: 0.4670 - val_accuracy: 0.8295\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.1609 - accuracy: 0.8344 - val_loss: 0.4797 - val_accuracy: 0.8251\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.9303 - accuracy: 0.8391 - val_loss: 0.4496 - val_accuracy: 0.8355\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.8200 - accuracy: 0.8426 - val_loss: 0.4877 - val_accuracy: 0.8243\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.7275 - accuracy: 0.8428 - val_loss: 0.4414 - val_accuracy: 0.8371\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.5665 - accuracy: 0.8480 - val_loss: 0.4699 - val_accuracy: 0.8293\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3928 - accuracy: 0.8516 - val_loss: 0.4768 - val_accuracy: 0.8227\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.2943 - accuracy: 0.8539 - val_loss: 0.4195 - val_accuracy: 0.8436\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.2151 - accuracy: 0.8564 - val_loss: 0.4849 - val_accuracy: 0.8275\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.0125 - accuracy: 0.8600 - val_loss: 0.4617 - val_accuracy: 0.8309\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.9160 - accuracy: 0.8617 - val_loss: 0.4384 - val_accuracy: 0.8428\n",
      "Epoch 28/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.8179 - accuracy: 0.8653 - val_loss: 0.4265 - val_accuracy: 0.8432\n",
      "Epoch 29/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.7849 - accuracy: 0.8652 - val_loss: 0.4369 - val_accuracy: 0.8411\n",
      "2975/2975 [==============================] - 18s 5ms/step\n",
      "372/372 [==============================] - 2s 6ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "150 1 (41.22, 2.8020706629205483) 0.8883774477129693\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 25ms/step - loss: 20.8118 - accuracy: 0.3983 - val_loss: 1.4313 - val_accuracy: 0.5013\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.5309 - accuracy: 0.5377 - val_loss: 1.1805 - val_accuracy: 0.5893\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.3150 - accuracy: 0.6024 - val_loss: 1.0236 - val_accuracy: 0.6359\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.7072 - accuracy: 0.6423 - val_loss: 0.9583 - val_accuracy: 0.6630\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.5919 - accuracy: 0.6751 - val_loss: 0.8759 - val_accuracy: 0.6763\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 10.6246 - accuracy: 0.7036 - val_loss: 0.7323 - val_accuracy: 0.7302\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.9790 - accuracy: 0.7230 - val_loss: 0.7206 - val_accuracy: 0.7329\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.3015 - accuracy: 0.7443 - val_loss: 0.6776 - val_accuracy: 0.7526\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.7728 - accuracy: 0.7612 - val_loss: 0.6506 - val_accuracy: 0.7618\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.3829 - accuracy: 0.7737 - val_loss: 0.5889 - val_accuracy: 0.7857\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.9678 - accuracy: 0.7868 - val_loss: 0.5328 - val_accuracy: 0.8037\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.6300 - accuracy: 0.7961 - val_loss: 0.5295 - val_accuracy: 0.8061\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.3260 - accuracy: 0.8044 - val_loss: 0.6337 - val_accuracy: 0.7708\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.9867 - accuracy: 0.8139 - val_loss: 0.4919 - val_accuracy: 0.8253\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.8360 - accuracy: 0.8171 - val_loss: 0.5009 - val_accuracy: 0.8187\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.6224 - accuracy: 0.8226 - val_loss: 0.5133 - val_accuracy: 0.8101\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.3559 - accuracy: 0.8296 - val_loss: 0.4988 - val_accuracy: 0.8176\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.1972 - accuracy: 0.8336 - val_loss: 0.4685 - val_accuracy: 0.8274\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.1182 - accuracy: 0.8347 - val_loss: 0.4851 - val_accuracy: 0.8222\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.9152 - accuracy: 0.8398 - val_loss: 0.4590 - val_accuracy: 0.8296\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.7878 - accuracy: 0.8426 - val_loss: 0.4323 - val_accuracy: 0.8449\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5835 - accuracy: 0.8484 - val_loss: 0.4500 - val_accuracy: 0.8313\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5289 - accuracy: 0.8482 - val_loss: 0.4685 - val_accuracy: 0.8274\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3772 - accuracy: 0.8516 - val_loss: 0.4375 - val_accuracy: 0.8422\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.2691 - accuracy: 0.8556 - val_loss: 0.4346 - val_accuracy: 0.8416\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.0933 - accuracy: 0.8576 - val_loss: 0.4330 - val_accuracy: 0.8447\n",
      "2975/2975 [==============================] - 18s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "150 2 (45.58, 2.6006922155456995) 0.9157369539366725\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 25ms/step - loss: 20.3998 - accuracy: 0.4147 - val_loss: 1.3873 - val_accuracy: 0.4954\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.3950 - accuracy: 0.5402 - val_loss: 1.3019 - val_accuracy: 0.5408\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.6307 - accuracy: 0.5928 - val_loss: 1.0822 - val_accuracy: 0.6029\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.8522 - accuracy: 0.6411 - val_loss: 1.0071 - val_accuracy: 0.6375\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.9583 - accuracy: 0.6640 - val_loss: 0.8405 - val_accuracy: 0.6947\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.7120 - accuracy: 0.7002 - val_loss: 0.8234 - val_accuracy: 0.6945\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.9029 - accuracy: 0.7268 - val_loss: 0.7141 - val_accuracy: 0.7355\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.2543 - accuracy: 0.7461 - val_loss: 0.6801 - val_accuracy: 0.7475\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 8.7242 - accuracy: 0.7633 - val_loss: 0.6652 - val_accuracy: 0.7607\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.3045 - accuracy: 0.7764 - val_loss: 0.5922 - val_accuracy: 0.7838\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.8292 - accuracy: 0.7907 - val_loss: 0.5934 - val_accuracy: 0.7810\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.5282 - accuracy: 0.7987 - val_loss: 0.5489 - val_accuracy: 0.8007\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.1790 - accuracy: 0.8084 - val_loss: 0.5231 - val_accuracy: 0.8074\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.9369 - accuracy: 0.8149 - val_loss: 0.5000 - val_accuracy: 0.8174\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.7198 - accuracy: 0.8194 - val_loss: 0.4610 - val_accuracy: 0.8356\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.5087 - accuracy: 0.8265 - val_loss: 0.4400 - val_accuracy: 0.8401\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.3277 - accuracy: 0.8299 - val_loss: 0.4762 - val_accuracy: 0.8280\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.1204 - accuracy: 0.8335 - val_loss: 0.4831 - val_accuracy: 0.8279\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.9974 - accuracy: 0.8375 - val_loss: 0.4390 - val_accuracy: 0.8407\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.8196 - accuracy: 0.8410 - val_loss: 0.4587 - val_accuracy: 0.8354\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.7089 - accuracy: 0.8438 - val_loss: 0.4454 - val_accuracy: 0.8357\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5606 - accuracy: 0.8471 - val_loss: 0.4486 - val_accuracy: 0.8395\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.4202 - accuracy: 0.8508 - val_loss: 0.4291 - val_accuracy: 0.8479\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3008 - accuracy: 0.8538 - val_loss: 0.4334 - val_accuracy: 0.8472\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.1776 - accuracy: 0.8566 - val_loss: 0.4360 - val_accuracy: 0.8444\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.0399 - accuracy: 0.8581 - val_loss: 0.4815 - val_accuracy: 0.8287\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.0326 - accuracy: 0.8586 - val_loss: 0.4514 - val_accuracy: 0.8370\n",
      "Epoch 28/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.7870 - accuracy: 0.8639 - val_loss: 0.4379 - val_accuracy: 0.8399\n",
      "2975/2975 [==============================] - 18s 5ms/step\n",
      "372/372 [==============================] - 2s 6ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "160 0 (44.92, 2.6141155291991205) 0.9112001750447254\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 25s 26ms/step - loss: 20.5476 - accuracy: 0.4074 - val_loss: 1.4691 - val_accuracy: 0.4644\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.5070 - accuracy: 0.5405 - val_loss: 1.2515 - val_accuracy: 0.5640\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.0414 - accuracy: 0.6103 - val_loss: 1.0989 - val_accuracy: 0.6063\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.5148 - accuracy: 0.6509 - val_loss: 0.8685 - val_accuracy: 0.6866\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.2120 - accuracy: 0.6880 - val_loss: 0.7902 - val_accuracy: 0.7099\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.3051 - accuracy: 0.7173 - val_loss: 0.7520 - val_accuracy: 0.7187\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.5775 - accuracy: 0.7347 - val_loss: 0.6711 - val_accuracy: 0.7543\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.0399 - accuracy: 0.7504 - val_loss: 0.6677 - val_accuracy: 0.7516\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.5819 - accuracy: 0.7673 - val_loss: 0.6039 - val_accuracy: 0.7779\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.1640 - accuracy: 0.7772 - val_loss: 0.5617 - val_accuracy: 0.7903\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.7831 - accuracy: 0.7894 - val_loss: 0.5545 - val_accuracy: 0.7940\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.4385 - accuracy: 0.7983 - val_loss: 0.5440 - val_accuracy: 0.7958\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.2125 - accuracy: 0.8051 - val_loss: 0.5139 - val_accuracy: 0.8101\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.9089 - accuracy: 0.8134 - val_loss: 0.5070 - val_accuracy: 0.8113\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.7079 - accuracy: 0.8189 - val_loss: 0.4777 - val_accuracy: 0.8201\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.4441 - accuracy: 0.8270 - val_loss: 0.5092 - val_accuracy: 0.8122\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.3316 - accuracy: 0.8283 - val_loss: 0.4708 - val_accuracy: 0.8269\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.1542 - accuracy: 0.8330 - val_loss: 0.4750 - val_accuracy: 0.8253\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.9012 - accuracy: 0.8386 - val_loss: 0.4609 - val_accuracy: 0.8298\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.8045 - accuracy: 0.8419 - val_loss: 0.4874 - val_accuracy: 0.8220\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.6259 - accuracy: 0.8445 - val_loss: 0.4397 - val_accuracy: 0.8381\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5392 - accuracy: 0.8471 - val_loss: 0.4597 - val_accuracy: 0.8328\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3478 - accuracy: 0.8510 - val_loss: 0.4278 - val_accuracy: 0.8453\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.2143 - accuracy: 0.8551 - val_loss: 0.4841 - val_accuracy: 0.8219\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.1724 - accuracy: 0.8563 - val_loss: 0.4509 - val_accuracy: 0.8348\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.9140 - accuracy: 0.8627 - val_loss: 0.4566 - val_accuracy: 0.8372\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.9715 - accuracy: 0.8594 - val_loss: 0.4296 - val_accuracy: 0.8476\n",
      "Epoch 28/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.7799 - accuracy: 0.8635 - val_loss: 0.4246 - val_accuracy: 0.8477\n",
      "Epoch 29/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.6799 - accuracy: 0.8668 - val_loss: 0.4665 - val_accuracy: 0.8357\n",
      "Epoch 30/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.6323 - accuracy: 0.8690 - val_loss: 0.4409 - val_accuracy: 0.8428\n",
      "Epoch 31/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744/744 [==============================] - 16s 22ms/step - loss: 4.3957 - accuracy: 0.8728 - val_loss: 0.4301 - val_accuracy: 0.8453\n",
      "Epoch 32/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.3296 - accuracy: 0.8734 - val_loss: 0.4277 - val_accuracy: 0.8472\n",
      "Epoch 33/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.3124 - accuracy: 0.8731 - val_loss: 0.4208 - val_accuracy: 0.8527\n",
      "Epoch 34/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.1769 - accuracy: 0.8776 - val_loss: 0.4559 - val_accuracy: 0.8457\n",
      "Epoch 35/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.1103 - accuracy: 0.8788 - val_loss: 0.4298 - val_accuracy: 0.8531\n",
      "Epoch 36/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 3.9377 - accuracy: 0.8822 - val_loss: 0.5088 - val_accuracy: 0.8244\n",
      "Epoch 37/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 3.8978 - accuracy: 0.8834 - val_loss: 0.4463 - val_accuracy: 0.8513\n",
      "Epoch 38/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 3.8564 - accuracy: 0.8843 - val_loss: 0.4721 - val_accuracy: 0.8411\n",
      "2975/2975 [==============================] - 18s 5ms/step\n",
      "372/372 [==============================] - 2s 6ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "160 1 (41.26, 3.1673964071457807) 0.8828374530727172\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 25ms/step - loss: 20.5143 - accuracy: 0.4069 - val_loss: 1.3972 - val_accuracy: 0.5101\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.4968 - accuracy: 0.5406 - val_loss: 1.1651 - val_accuracy: 0.5958\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.2736 - accuracy: 0.6052 - val_loss: 1.0311 - val_accuracy: 0.6339\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.9748 - accuracy: 0.6377 - val_loss: 0.9301 - val_accuracy: 0.6642\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.8541 - accuracy: 0.6685 - val_loss: 0.8741 - val_accuracy: 0.6762\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.9666 - accuracy: 0.6935 - val_loss: 0.8190 - val_accuracy: 0.7046\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.2321 - accuracy: 0.7149 - val_loss: 0.7732 - val_accuracy: 0.7163\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.5713 - accuracy: 0.7349 - val_loss: 0.6604 - val_accuracy: 0.7558\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.9548 - accuracy: 0.7536 - val_loss: 0.6305 - val_accuracy: 0.7694\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.4541 - accuracy: 0.7698 - val_loss: 0.6012 - val_accuracy: 0.7755\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.0657 - accuracy: 0.7818 - val_loss: 0.6084 - val_accuracy: 0.7737\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 7.6829 - accuracy: 0.7935 - val_loss: 0.5774 - val_accuracy: 0.7909\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.3368 - accuracy: 0.8034 - val_loss: 0.5506 - val_accuracy: 0.7964\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 7.0539 - accuracy: 0.8099 - val_loss: 0.5148 - val_accuracy: 0.8118\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.8611 - accuracy: 0.8149 - val_loss: 0.4948 - val_accuracy: 0.8165\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.6408 - accuracy: 0.8206 - val_loss: 0.4850 - val_accuracy: 0.8237\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.3766 - accuracy: 0.8271 - val_loss: 0.4938 - val_accuracy: 0.8174\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.2146 - accuracy: 0.8309 - val_loss: 0.5018 - val_accuracy: 0.8143\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.9847 - accuracy: 0.8374 - val_loss: 0.5229 - val_accuracy: 0.8095\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.9492 - accuracy: 0.8387 - val_loss: 0.5011 - val_accuracy: 0.8168\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.7004 - accuracy: 0.8444 - val_loss: 0.4685 - val_accuracy: 0.8296\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5504 - accuracy: 0.8474 - val_loss: 0.4271 - val_accuracy: 0.8444\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5260 - accuracy: 0.8472 - val_loss: 0.4920 - val_accuracy: 0.8204\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3533 - accuracy: 0.8510 - val_loss: 0.4269 - val_accuracy: 0.8447\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.1625 - accuracy: 0.8562 - val_loss: 0.4373 - val_accuracy: 0.8405\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.0364 - accuracy: 0.8587 - val_loss: 0.4661 - val_accuracy: 0.8375\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.9039 - accuracy: 0.8619 - val_loss: 0.4443 - val_accuracy: 0.8377\n",
      "2975/2975 [==============================] - 18s 5ms/step\n",
      "372/372 [==============================] - 2s 6ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "160 2 (45.9, 2.491987158875422) 0.9198719334681509\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 26s 27ms/step - loss: 20.5575 - accuracy: 0.4127 - val_loss: 1.3287 - val_accuracy: 0.5479\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.5481 - accuracy: 0.5354 - val_loss: 1.1204 - val_accuracy: 0.6172\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.8766 - accuracy: 0.5883 - val_loss: 1.0543 - val_accuracy: 0.6302\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 13.1901 - accuracy: 0.6324 - val_loss: 1.0049 - val_accuracy: 0.6380\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.3788 - accuracy: 0.6526 - val_loss: 0.9304 - val_accuracy: 0.6620\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.3711 - accuracy: 0.6812 - val_loss: 0.7850 - val_accuracy: 0.7170\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.5055 - accuracy: 0.7088 - val_loss: 0.7321 - val_accuracy: 0.7337\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.9304 - accuracy: 0.7257 - val_loss: 0.6942 - val_accuracy: 0.7407\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.2653 - accuracy: 0.7469 - val_loss: 0.6897 - val_accuracy: 0.7448\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.7287 - accuracy: 0.7622 - val_loss: 0.6397 - val_accuracy: 0.7639\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.1795 - accuracy: 0.7793 - val_loss: 0.5861 - val_accuracy: 0.7842\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.8798 - accuracy: 0.7886 - val_loss: 0.6009 - val_accuracy: 0.7752\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.4156 - accuracy: 0.8009 - val_loss: 0.5624 - val_accuracy: 0.7921\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.1528 - accuracy: 0.8091 - val_loss: 0.5444 - val_accuracy: 0.7986\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.9600 - accuracy: 0.8130 - val_loss: 0.5418 - val_accuracy: 0.8058\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.7239 - accuracy: 0.8193 - val_loss: 0.5215 - val_accuracy: 0.8080\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.4612 - accuracy: 0.8270 - val_loss: 0.5629 - val_accuracy: 0.7992\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.2332 - accuracy: 0.8304 - val_loss: 0.5010 - val_accuracy: 0.8171\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 6.1770 - accuracy: 0.8324 - val_loss: 0.4709 - val_accuracy: 0.8271\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 5.9330 - accuracy: 0.8384 - val_loss: 0.5065 - val_accuracy: 0.8095\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.8430 - accuracy: 0.8406 - val_loss: 0.5079 - val_accuracy: 0.8153\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.6396 - accuracy: 0.8458 - val_loss: 0.4130 - val_accuracy: 0.8468\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5121 - accuracy: 0.8495 - val_loss: 0.4543 - val_accuracy: 0.8384\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.4813 - accuracy: 0.8502 - val_loss: 0.4425 - val_accuracy: 0.8349\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3008 - accuracy: 0.8540 - val_loss: 0.5001 - val_accuracy: 0.8179\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.2106 - accuracy: 0.8562 - val_loss: 0.4602 - val_accuracy: 0.8327\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.0803 - accuracy: 0.8593 - val_loss: 0.4733 - val_accuracy: 0.8288\n",
      "2975/2975 [==============================] - 18s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "170 0 (41.02, 3.30145422503478) 0.8765588999248443\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 25ms/step - loss: 20.4568 - accuracy: 0.4116 - val_loss: 1.4621 - val_accuracy: 0.4873\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.1573 - accuracy: 0.5519 - val_loss: 1.1377 - val_accuracy: 0.5986\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 13.9960 - accuracy: 0.6127 - val_loss: 1.0176 - val_accuracy: 0.6357\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.9020 - accuracy: 0.6391 - val_loss: 0.9490 - val_accuracy: 0.6631\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.5800 - accuracy: 0.6762 - val_loss: 0.8241 - val_accuracy: 0.6994\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.6352 - accuracy: 0.7059 - val_loss: 0.7431 - val_accuracy: 0.7257\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.8095 - accuracy: 0.7318 - val_loss: 0.7571 - val_accuracy: 0.7194\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.1804 - accuracy: 0.7487 - val_loss: 0.6164 - val_accuracy: 0.7783\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.6709 - accuracy: 0.7659 - val_loss: 0.5888 - val_accuracy: 0.7835\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.2515 - accuracy: 0.7779 - val_loss: 0.6224 - val_accuracy: 0.7711\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.9125 - accuracy: 0.7876 - val_loss: 0.5907 - val_accuracy: 0.7875\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.5419 - accuracy: 0.7995 - val_loss: 0.5514 - val_accuracy: 0.8027\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.3717 - accuracy: 0.8027 - val_loss: 0.5484 - val_accuracy: 0.7949\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.0248 - accuracy: 0.8131 - val_loss: 0.5195 - val_accuracy: 0.8133\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.8020 - accuracy: 0.8187 - val_loss: 0.4817 - val_accuracy: 0.8212\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.6201 - accuracy: 0.8221 - val_loss: 0.5644 - val_accuracy: 0.7918\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.4009 - accuracy: 0.8277 - val_loss: 0.5144 - val_accuracy: 0.8090\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.3016 - accuracy: 0.8306 - val_loss: 0.4717 - val_accuracy: 0.8284\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.0894 - accuracy: 0.8353 - val_loss: 0.4712 - val_accuracy: 0.8270\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.8616 - accuracy: 0.8394 - val_loss: 0.4850 - val_accuracy: 0.8248\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.7765 - accuracy: 0.8412 - val_loss: 0.4585 - val_accuracy: 0.8306\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.6739 - accuracy: 0.8440 - val_loss: 0.4733 - val_accuracy: 0.8276\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.4644 - accuracy: 0.8498 - val_loss: 0.4801 - val_accuracy: 0.8244\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3163 - accuracy: 0.8529 - val_loss: 0.4472 - val_accuracy: 0.8368\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.2496 - accuracy: 0.8547 - val_loss: 0.4631 - val_accuracy: 0.8263\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.0928 - accuracy: 0.8574 - val_loss: 0.4344 - val_accuracy: 0.8425\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 4.9867 - accuracy: 0.8603 - val_loss: 0.4756 - val_accuracy: 0.8299\n",
      "Epoch 28/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 4.8610 - accuracy: 0.8629 - val_loss: 0.4255 - val_accuracy: 0.8442\n",
      "Epoch 29/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 4.8201 - accuracy: 0.8644 - val_loss: 0.4232 - val_accuracy: 0.8488\n",
      "Epoch 30/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 4.6692 - accuracy: 0.8662 - val_loss: 0.4142 - val_accuracy: 0.8480\n",
      "Epoch 31/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 4.5596 - accuracy: 0.8700 - val_loss: 0.4166 - val_accuracy: 0.8516\n",
      "Epoch 32/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 4.4528 - accuracy: 0.8718 - val_loss: 0.4471 - val_accuracy: 0.8423\n",
      "Epoch 33/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 4.2971 - accuracy: 0.8751 - val_loss: 0.4711 - val_accuracy: 0.8322\n",
      "Epoch 34/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 4.2045 - accuracy: 0.8771 - val_loss: 0.4184 - val_accuracy: 0.8522\n",
      "Epoch 35/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.1373 - accuracy: 0.8784 - val_loss: 0.4224 - val_accuracy: 0.8501\n",
      "2975/2975 [==============================] - 18s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "170 1 (42.82, 2.984560269118384) 0.8994596022620057\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 25s 25ms/step - loss: 20.6507 - accuracy: 0.4040 - val_loss: 1.4029 - val_accuracy: 0.5147\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 16.3436 - accuracy: 0.5456 - val_loss: 1.1307 - val_accuracy: 0.6020\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 13.9612 - accuracy: 0.6141 - val_loss: 0.9667 - val_accuracy: 0.6601\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 12.2845 - accuracy: 0.6582 - val_loss: 0.8740 - val_accuracy: 0.6866\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 11.1352 - accuracy: 0.6909 - val_loss: 0.8274 - val_accuracy: 0.6978\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 10.3671 - accuracy: 0.7138 - val_loss: 0.7183 - val_accuracy: 0.7347\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 9.5885 - accuracy: 0.7378 - val_loss: 0.6531 - val_accuracy: 0.7604\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 8.9927 - accuracy: 0.7553 - val_loss: 0.6573 - val_accuracy: 0.7614\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 8.4869 - accuracy: 0.7705 - val_loss: 0.6167 - val_accuracy: 0.7699\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744/744 [==============================] - 17s 22ms/step - loss: 8.0561 - accuracy: 0.7839 - val_loss: 0.5749 - val_accuracy: 0.7919\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 7.6976 - accuracy: 0.7939 - val_loss: 0.5754 - val_accuracy: 0.7881\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 7.4131 - accuracy: 0.8023 - val_loss: 0.5250 - val_accuracy: 0.8063\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 7.1713 - accuracy: 0.8087 - val_loss: 0.5510 - val_accuracy: 0.7983\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.9496 - accuracy: 0.8132 - val_loss: 0.5179 - val_accuracy: 0.8102\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.6346 - accuracy: 0.8233 - val_loss: 0.5062 - val_accuracy: 0.8160\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 6.4751 - accuracy: 0.8262 - val_loss: 0.5203 - val_accuracy: 0.8069\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 6.3224 - accuracy: 0.8301 - val_loss: 0.5136 - val_accuracy: 0.8140\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 6.1264 - accuracy: 0.8339 - val_loss: 0.4938 - val_accuracy: 0.8205\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.9500 - accuracy: 0.8394 - val_loss: 0.4895 - val_accuracy: 0.8238\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.8196 - accuracy: 0.8415 - val_loss: 0.4597 - val_accuracy: 0.8317\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 5.6918 - accuracy: 0.8460 - val_loss: 0.4373 - val_accuracy: 0.8428\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.5872 - accuracy: 0.8473 - val_loss: 0.4416 - val_accuracy: 0.8370\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.3915 - accuracy: 0.8524 - val_loss: 0.4918 - val_accuracy: 0.8248\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.4054 - accuracy: 0.8502 - val_loss: 0.4423 - val_accuracy: 0.8403\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.1253 - accuracy: 0.8568 - val_loss: 0.4467 - val_accuracy: 0.8364\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.0007 - accuracy: 0.8598 - val_loss: 0.4486 - val_accuracy: 0.8382\n",
      "2975/2975 [==============================] - 20s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "170 2 (45.5, 2.8792360097775935) 0.9136513358056695\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 25ms/step - loss: 20.7267 - accuracy: 0.4018 - val_loss: 1.4288 - val_accuracy: 0.5007\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 16.3550 - accuracy: 0.5459 - val_loss: 1.1920 - val_accuracy: 0.5825\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 14.4049 - accuracy: 0.6015 - val_loss: 1.0659 - val_accuracy: 0.6206\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 13.0447 - accuracy: 0.6377 - val_loss: 0.9587 - val_accuracy: 0.6644\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 11.7292 - accuracy: 0.6722 - val_loss: 0.8255 - val_accuracy: 0.7045\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 10.6465 - accuracy: 0.7059 - val_loss: 0.7847 - val_accuracy: 0.7131\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 9.8752 - accuracy: 0.7291 - val_loss: 0.6814 - val_accuracy: 0.7501\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 9.2194 - accuracy: 0.7481 - val_loss: 0.7079 - val_accuracy: 0.7384\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 8.6417 - accuracy: 0.7677 - val_loss: 0.6373 - val_accuracy: 0.7638\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 8.1241 - accuracy: 0.7801 - val_loss: 0.5915 - val_accuracy: 0.7848\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 7.8460 - accuracy: 0.7898 - val_loss: 0.5623 - val_accuracy: 0.7991\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 7.4349 - accuracy: 0.8018 - val_loss: 0.5781 - val_accuracy: 0.7879\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.2230 - accuracy: 0.8071 - val_loss: 0.5008 - val_accuracy: 0.8206\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.9751 - accuracy: 0.8134 - val_loss: 0.5091 - val_accuracy: 0.8088\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.6959 - accuracy: 0.8211 - val_loss: 0.5117 - val_accuracy: 0.8138\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.5133 - accuracy: 0.8268 - val_loss: 0.4763 - val_accuracy: 0.8279\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 6.3052 - accuracy: 0.8291 - val_loss: 0.5351 - val_accuracy: 0.8073\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 6.1682 - accuracy: 0.8327 - val_loss: 0.4848 - val_accuracy: 0.8190\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.0104 - accuracy: 0.8367 - val_loss: 0.4585 - val_accuracy: 0.8343\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 5.8213 - accuracy: 0.8398 - val_loss: 0.4520 - val_accuracy: 0.8360\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.6743 - accuracy: 0.8444 - val_loss: 0.5207 - val_accuracy: 0.8153\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.6239 - accuracy: 0.8450 - val_loss: 0.5029 - val_accuracy: 0.8198\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.4248 - accuracy: 0.8499 - val_loss: 0.4566 - val_accuracy: 0.8354\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3007 - accuracy: 0.8536 - val_loss: 0.4419 - val_accuracy: 0.8390\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.1191 - accuracy: 0.8570 - val_loss: 0.4621 - val_accuracy: 0.8359\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 5.0662 - accuracy: 0.8582 - val_loss: 0.4476 - val_accuracy: 0.8388\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 4.8697 - accuracy: 0.8636 - val_loss: 0.4485 - val_accuracy: 0.8443\n",
      "Epoch 28/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 4.9459 - accuracy: 0.8601 - val_loss: 0.5155 - val_accuracy: 0.8150\n",
      "Epoch 29/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 4.7541 - accuracy: 0.8648 - val_loss: 0.4193 - val_accuracy: 0.8497\n",
      "Epoch 30/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 4.6029 - accuracy: 0.8675 - val_loss: 0.4370 - val_accuracy: 0.8493\n",
      "Epoch 31/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 4.4290 - accuracy: 0.8719 - val_loss: 0.4303 - val_accuracy: 0.8460\n",
      "Epoch 32/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 4.3702 - accuracy: 0.8730 - val_loss: 0.4935 - val_accuracy: 0.8288\n",
      "Epoch 33/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 4.2485 - accuracy: 0.8765 - val_loss: 0.4338 - val_accuracy: 0.8487\n",
      "Epoch 34/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 4.1998 - accuracy: 0.8769 - val_loss: 0.4490 - val_accuracy: 0.8480\n",
      "2975/2975 [==============================] - 18s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "180 0 (41.48, 3.2387651967995463) 0.8853004644558334\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 25ms/step - loss: 20.4830 - accuracy: 0.4116 - val_loss: 1.3782 - val_accuracy: 0.5171\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 17.0978 - accuracy: 0.5194 - val_loss: 1.2356 - val_accuracy: 0.5747\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.6066 - accuracy: 0.5939 - val_loss: 1.0511 - val_accuracy: 0.6299\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 12.9467 - accuracy: 0.6395 - val_loss: 0.9444 - val_accuracy: 0.6506\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 11.7761 - accuracy: 0.6714 - val_loss: 0.9264 - val_accuracy: 0.6679\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.9335 - accuracy: 0.6958 - val_loss: 0.8218 - val_accuracy: 0.6968\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.0758 - accuracy: 0.7199 - val_loss: 0.7020 - val_accuracy: 0.7394\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 9.4991 - accuracy: 0.7392 - val_loss: 0.6811 - val_accuracy: 0.7500\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.9426 - accuracy: 0.7561 - val_loss: 0.6395 - val_accuracy: 0.7653\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.5197 - accuracy: 0.7693 - val_loss: 0.5983 - val_accuracy: 0.7784\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 8.0976 - accuracy: 0.7807 - val_loss: 0.5917 - val_accuracy: 0.7779\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 7.7430 - accuracy: 0.7922 - val_loss: 0.5169 - val_accuracy: 0.8110\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 7.4541 - accuracy: 0.8007 - val_loss: 0.6357 - val_accuracy: 0.7701\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 7.2091 - accuracy: 0.8061 - val_loss: 0.5413 - val_accuracy: 0.8045\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 6.9339 - accuracy: 0.8133 - val_loss: 0.5025 - val_accuracy: 0.8172\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.7286 - accuracy: 0.8191 - val_loss: 0.4758 - val_accuracy: 0.8224\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.5965 - accuracy: 0.8224 - val_loss: 0.5073 - val_accuracy: 0.8099\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.3788 - accuracy: 0.8279 - val_loss: 0.4636 - val_accuracy: 0.8306\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.2327 - accuracy: 0.8307 - val_loss: 0.4569 - val_accuracy: 0.8306\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.0682 - accuracy: 0.8359 - val_loss: 0.4499 - val_accuracy: 0.8323\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.8932 - accuracy: 0.8384 - val_loss: 0.4593 - val_accuracy: 0.8322\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.7370 - accuracy: 0.8418 - val_loss: 0.5123 - val_accuracy: 0.8119\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 5.6390 - accuracy: 0.8453 - val_loss: 0.4612 - val_accuracy: 0.8332\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 5.4370 - accuracy: 0.8491 - val_loss: 0.4441 - val_accuracy: 0.8326\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.3578 - accuracy: 0.8502 - val_loss: 0.5021 - val_accuracy: 0.8161\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.2817 - accuracy: 0.8529 - val_loss: 0.4466 - val_accuracy: 0.8375\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.0651 - accuracy: 0.8573 - val_loss: 0.4501 - val_accuracy: 0.8395\n",
      "Epoch 28/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.0016 - accuracy: 0.8579 - val_loss: 0.4488 - val_accuracy: 0.8393\n",
      "Epoch 29/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 4.8389 - accuracy: 0.8618 - val_loss: 0.4366 - val_accuracy: 0.8446\n",
      "Epoch 30/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 4.6804 - accuracy: 0.8659 - val_loss: 0.4526 - val_accuracy: 0.8383\n",
      "Epoch 31/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 4.6592 - accuracy: 0.8658 - val_loss: 0.4424 - val_accuracy: 0.8407\n",
      "Epoch 32/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 4.4812 - accuracy: 0.8704 - val_loss: 0.4919 - val_accuracy: 0.8227\n",
      "Epoch 33/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 4.5076 - accuracy: 0.8705 - val_loss: 0.4455 - val_accuracy: 0.8450\n",
      "Epoch 34/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 4.3172 - accuracy: 0.8737 - val_loss: 0.4485 - val_accuracy: 0.8388\n",
      "2975/2975 [==============================] - 18s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "180 1 (43.38, 2.6221365334398588) 0.9070133219753882\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 25s 26ms/step - loss: 20.5243 - accuracy: 0.4075 - val_loss: 1.4263 - val_accuracy: 0.5176\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 16.3912 - accuracy: 0.5433 - val_loss: 1.1596 - val_accuracy: 0.5951\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 14.2706 - accuracy: 0.6027 - val_loss: 1.0390 - val_accuracy: 0.6278\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 12.8159 - accuracy: 0.6417 - val_loss: 0.9047 - val_accuracy: 0.6783\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 11.5196 - accuracy: 0.6770 - val_loss: 0.8790 - val_accuracy: 0.6782\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 10.5477 - accuracy: 0.7038 - val_loss: 0.7648 - val_accuracy: 0.7168\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 9.8706 - accuracy: 0.7273 - val_loss: 0.7148 - val_accuracy: 0.7363\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 18s 24ms/step - loss: 9.2697 - accuracy: 0.7448 - val_loss: 0.6425 - val_accuracy: 0.7599\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.6788 - accuracy: 0.7634 - val_loss: 0.6406 - val_accuracy: 0.7664\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.2379 - accuracy: 0.7779 - val_loss: 0.5625 - val_accuracy: 0.7978\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.8769 - accuracy: 0.7876 - val_loss: 0.5756 - val_accuracy: 0.7893\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.5126 - accuracy: 0.7981 - val_loss: 0.5228 - val_accuracy: 0.8079\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.1896 - accuracy: 0.8071 - val_loss: 0.5386 - val_accuracy: 0.8061\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.0047 - accuracy: 0.8123 - val_loss: 0.4961 - val_accuracy: 0.8169\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.8086 - accuracy: 0.8173 - val_loss: 0.5318 - val_accuracy: 0.8037\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 6.5400 - accuracy: 0.8237 - val_loss: 0.5073 - val_accuracy: 0.8124\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 6.3663 - accuracy: 0.8274 - val_loss: 0.5093 - val_accuracy: 0.8153\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 6.1662 - accuracy: 0.8321 - val_loss: 0.4776 - val_accuracy: 0.8238\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.0556 - accuracy: 0.8360 - val_loss: 0.4694 - val_accuracy: 0.8283\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.8750 - accuracy: 0.8399 - val_loss: 0.4502 - val_accuracy: 0.8354\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.7799 - accuracy: 0.8419 - val_loss: 0.4782 - val_accuracy: 0.8243\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5399 - accuracy: 0.8481 - val_loss: 0.4765 - val_accuracy: 0.8235\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5056 - accuracy: 0.8475 - val_loss: 0.4591 - val_accuracy: 0.8353\n",
      "Epoch 24/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3060 - accuracy: 0.8537 - val_loss: 0.4779 - val_accuracy: 0.8239\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.1964 - accuracy: 0.8565 - val_loss: 0.4723 - val_accuracy: 0.8312\n",
      "2975/2975 [==============================] - 17s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "180 2 (42.04, 3.0063931878581687) 0.8912550949669513\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 24ms/step - loss: 20.3495 - accuracy: 0.4134 - val_loss: 1.3842 - val_accuracy: 0.5113\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.0751 - accuracy: 0.5529 - val_loss: 1.1350 - val_accuracy: 0.5993\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.1442 - accuracy: 0.6078 - val_loss: 1.0825 - val_accuracy: 0.6208\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.6393 - accuracy: 0.6466 - val_loss: 0.9254 - val_accuracy: 0.6658\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.4667 - accuracy: 0.6809 - val_loss: 0.8169 - val_accuracy: 0.7092\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 10.4255 - accuracy: 0.7118 - val_loss: 0.7670 - val_accuracy: 0.7200\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 9.5258 - accuracy: 0.7405 - val_loss: 0.6869 - val_accuracy: 0.7473\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 8.8836 - accuracy: 0.7601 - val_loss: 0.6036 - val_accuracy: 0.7804\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 8.3235 - accuracy: 0.7762 - val_loss: 0.6340 - val_accuracy: 0.7740\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 7.9791 - accuracy: 0.7869 - val_loss: 0.5826 - val_accuracy: 0.7932\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 7.6658 - accuracy: 0.7944 - val_loss: 0.5650 - val_accuracy: 0.7960\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.4186 - accuracy: 0.8024 - val_loss: 0.5484 - val_accuracy: 0.8012\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.0817 - accuracy: 0.8097 - val_loss: 0.5364 - val_accuracy: 0.8064\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.9012 - accuracy: 0.8153 - val_loss: 0.4989 - val_accuracy: 0.8166\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.7188 - accuracy: 0.8208 - val_loss: 0.5347 - val_accuracy: 0.8058\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.4708 - accuracy: 0.8255 - val_loss: 0.4832 - val_accuracy: 0.8244\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.3234 - accuracy: 0.8304 - val_loss: 0.4930 - val_accuracy: 0.8193\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.2265 - accuracy: 0.8321 - val_loss: 0.4889 - val_accuracy: 0.8213\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.9964 - accuracy: 0.8378 - val_loss: 0.4548 - val_accuracy: 0.8375\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.8436 - accuracy: 0.8413 - val_loss: 0.4697 - val_accuracy: 0.8290\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.6951 - accuracy: 0.8441 - val_loss: 0.5195 - val_accuracy: 0.8139\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.6059 - accuracy: 0.8462 - val_loss: 0.4390 - val_accuracy: 0.8423\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5274 - accuracy: 0.8480 - val_loss: 0.4647 - val_accuracy: 0.8314\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3518 - accuracy: 0.8511 - val_loss: 0.4717 - val_accuracy: 0.8332\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.1823 - accuracy: 0.8554 - val_loss: 0.4171 - val_accuracy: 0.8505\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.0891 - accuracy: 0.8574 - val_loss: 0.4282 - val_accuracy: 0.8453\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.9364 - accuracy: 0.8605 - val_loss: 0.4292 - val_accuracy: 0.8433\n",
      "Epoch 28/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.8324 - accuracy: 0.8634 - val_loss: 0.4486 - val_accuracy: 0.8420\n",
      "Epoch 29/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.8203 - accuracy: 0.8644 - val_loss: 0.6084 - val_accuracy: 0.8025\n",
      "Epoch 30/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.6943 - accuracy: 0.8670 - val_loss: 0.4459 - val_accuracy: 0.8423\n",
      "2975/2975 [==============================] - 17s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "190 0 (46.16, 2.9007585214905425) 0.9232012518988065\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 26s 24ms/step - loss: 20.2813 - accuracy: 0.4197 - val_loss: 1.3920 - val_accuracy: 0.5152\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.0366 - accuracy: 0.5548 - val_loss: 1.2459 - val_accuracy: 0.5549\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 13.9325 - accuracy: 0.6148 - val_loss: 1.0005 - val_accuracy: 0.6413\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.4107 - accuracy: 0.6525 - val_loss: 0.9165 - val_accuracy: 0.6647\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.1885 - accuracy: 0.6882 - val_loss: 0.8442 - val_accuracy: 0.6910\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.1020 - accuracy: 0.7215 - val_loss: 0.7704 - val_accuracy: 0.7145\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.4143 - accuracy: 0.7431 - val_loss: 0.6794 - val_accuracy: 0.7490\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.7900 - accuracy: 0.7601 - val_loss: 0.6435 - val_accuracy: 0.7621\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.2945 - accuracy: 0.7751 - val_loss: 0.6083 - val_accuracy: 0.7770\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.9974 - accuracy: 0.7854 - val_loss: 0.5392 - val_accuracy: 0.8069\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.6087 - accuracy: 0.7958 - val_loss: 0.5271 - val_accuracy: 0.8055\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.2932 - accuracy: 0.8052 - val_loss: 0.5398 - val_accuracy: 0.8022\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.0596 - accuracy: 0.8112 - val_loss: 0.5555 - val_accuracy: 0.7969\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.8053 - accuracy: 0.8177 - val_loss: 0.5749 - val_accuracy: 0.7869\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.6019 - accuracy: 0.8222 - val_loss: 0.5145 - val_accuracy: 0.8095\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.4460 - accuracy: 0.8269 - val_loss: 0.4881 - val_accuracy: 0.8269\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.2375 - accuracy: 0.8321 - val_loss: 0.4607 - val_accuracy: 0.8301\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.0545 - accuracy: 0.8364 - val_loss: 0.4638 - val_accuracy: 0.8325\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.9325 - accuracy: 0.8377 - val_loss: 0.4543 - val_accuracy: 0.8339\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.7669 - accuracy: 0.8419 - val_loss: 0.4760 - val_accuracy: 0.8258\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.6289 - accuracy: 0.8467 - val_loss: 0.4488 - val_accuracy: 0.8341\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.4895 - accuracy: 0.8493 - val_loss: 0.4717 - val_accuracy: 0.8291\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3502 - accuracy: 0.8514 - val_loss: 0.4676 - val_accuracy: 0.8306\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3282 - accuracy: 0.8521 - val_loss: 0.4802 - val_accuracy: 0.8274\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.1702 - accuracy: 0.8561 - val_loss: 0.4378 - val_accuracy: 0.8405\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.0801 - accuracy: 0.8586 - val_loss: 0.4377 - val_accuracy: 0.8388\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.9087 - accuracy: 0.8618 - val_loss: 0.4444 - val_accuracy: 0.8372\n",
      "Epoch 28/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.8289 - accuracy: 0.8639 - val_loss: 0.4375 - val_accuracy: 0.8405\n",
      "Epoch 29/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 4.7005 - accuracy: 0.8667 - val_loss: 0.4395 - val_accuracy: 0.8427\n",
      "Epoch 30/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.5374 - accuracy: 0.8702 - val_loss: 0.4204 - val_accuracy: 0.8490\n",
      "Epoch 31/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.5243 - accuracy: 0.8697 - val_loss: 0.4463 - val_accuracy: 0.8425\n",
      "Epoch 32/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.4536 - accuracy: 0.8719 - val_loss: 0.4263 - val_accuracy: 0.8480\n",
      "Epoch 33/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.3488 - accuracy: 0.8748 - val_loss: 0.4489 - val_accuracy: 0.8411\n",
      "Epoch 34/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.1021 - accuracy: 0.8785 - val_loss: 0.4427 - val_accuracy: 0.8459\n",
      "Epoch 35/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.0560 - accuracy: 0.8801 - val_loss: 0.4166 - val_accuracy: 0.8571\n",
      "Epoch 36/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.0044 - accuracy: 0.8819 - val_loss: 0.4406 - val_accuracy: 0.8481\n",
      "Epoch 37/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 3.9206 - accuracy: 0.8822 - val_loss: 0.4481 - val_accuracy: 0.8515\n",
      "Epoch 38/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 3.7762 - accuracy: 0.8871 - val_loss: 0.4309 - val_accuracy: 0.8495\n",
      "Epoch 39/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 3.6364 - accuracy: 0.8894 - val_loss: 0.4747 - val_accuracy: 0.8419\n",
      "Epoch 40/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 3.7717 - accuracy: 0.8872 - val_loss: 0.4619 - val_accuracy: 0.8469\n",
      "2975/2975 [==============================] - 17s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "190 1 (44.06, 2.9893812068720846) 0.9046971058170161\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 24ms/step - loss: 20.4916 - accuracy: 0.4067 - val_loss: 1.3996 - val_accuracy: 0.5182\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.2059 - accuracy: 0.5470 - val_loss: 1.1496 - val_accuracy: 0.6005\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.0267 - accuracy: 0.6073 - val_loss: 1.0173 - val_accuracy: 0.6349\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.2519 - accuracy: 0.6582 - val_loss: 0.8666 - val_accuracy: 0.6830\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.1036 - accuracy: 0.6909 - val_loss: 0.7902 - val_accuracy: 0.7136\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.1770 - accuracy: 0.7203 - val_loss: 0.7748 - val_accuracy: 0.7136\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.4124 - accuracy: 0.7444 - val_loss: 0.6461 - val_accuracy: 0.7646\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.7411 - accuracy: 0.7630 - val_loss: 0.5903 - val_accuracy: 0.7865\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.2796 - accuracy: 0.7790 - val_loss: 0.6518 - val_accuracy: 0.7632\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.9192 - accuracy: 0.7885 - val_loss: 0.5776 - val_accuracy: 0.7873\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.4912 - accuracy: 0.8015 - val_loss: 0.5387 - val_accuracy: 0.8051\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.2856 - accuracy: 0.8057 - val_loss: 0.5534 - val_accuracy: 0.7937\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.9574 - accuracy: 0.8146 - val_loss: 0.5475 - val_accuracy: 0.8022\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.7766 - accuracy: 0.8197 - val_loss: 0.4985 - val_accuracy: 0.8217\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.6037 - accuracy: 0.8238 - val_loss: 0.4666 - val_accuracy: 0.8288\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.4213 - accuracy: 0.8271 - val_loss: 0.4645 - val_accuracy: 0.8320\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.1965 - accuracy: 0.8327 - val_loss: 0.5150 - val_accuracy: 0.8202\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.0971 - accuracy: 0.8367 - val_loss: 0.4727 - val_accuracy: 0.8269\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.8648 - accuracy: 0.8419 - val_loss: 0.4711 - val_accuracy: 0.8290\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.7990 - accuracy: 0.8428 - val_loss: 0.4564 - val_accuracy: 0.8362\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.6465 - accuracy: 0.8470 - val_loss: 0.4608 - val_accuracy: 0.8332\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.4441 - accuracy: 0.8506 - val_loss: 0.4392 - val_accuracy: 0.8413\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3714 - accuracy: 0.8526 - val_loss: 0.4153 - val_accuracy: 0.8527\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.2429 - accuracy: 0.8556 - val_loss: 0.4757 - val_accuracy: 0.8252\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.1076 - accuracy: 0.8577 - val_loss: 0.4120 - val_accuracy: 0.8522\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.9946 - accuracy: 0.8615 - val_loss: 0.4623 - val_accuracy: 0.8346\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.9120 - accuracy: 0.8614 - val_loss: 0.4514 - val_accuracy: 0.8345\n",
      "Epoch 28/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.7994 - accuracy: 0.8645 - val_loss: 0.4294 - val_accuracy: 0.8449\n",
      "Epoch 29/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.6496 - accuracy: 0.8676 - val_loss: 0.4260 - val_accuracy: 0.8492\n",
      "Epoch 30/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.5728 - accuracy: 0.8697 - val_loss: 0.4692 - val_accuracy: 0.8339\n",
      "2975/2975 [==============================] - 17s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "190 2 (44.5, 2.8442925306655784) 0.9043468621145584\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 24ms/step - loss: 20.5250 - accuracy: 0.4089 - val_loss: 1.4814 - val_accuracy: 0.4707\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.2825 - accuracy: 0.5490 - val_loss: 1.2728 - val_accuracy: 0.5461\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.3126 - accuracy: 0.6048 - val_loss: 1.0600 - val_accuracy: 0.6125\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.9221 - accuracy: 0.6393 - val_loss: 0.9021 - val_accuracy: 0.6754\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744/744 [==============================] - 16s 22ms/step - loss: 11.6311 - accuracy: 0.6753 - val_loss: 0.8791 - val_accuracy: 0.6806\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.6665 - accuracy: 0.7042 - val_loss: 0.8106 - val_accuracy: 0.7029\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.8850 - accuracy: 0.7271 - val_loss: 0.7802 - val_accuracy: 0.7176\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.2065 - accuracy: 0.7483 - val_loss: 0.6894 - val_accuracy: 0.7519\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.6494 - accuracy: 0.7645 - val_loss: 0.6367 - val_accuracy: 0.7719\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.1815 - accuracy: 0.7800 - val_loss: 0.6255 - val_accuracy: 0.7689\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.7884 - accuracy: 0.7912 - val_loss: 0.5793 - val_accuracy: 0.7869\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.4688 - accuracy: 0.7988 - val_loss: 0.5390 - val_accuracy: 0.8047\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.2368 - accuracy: 0.8056 - val_loss: 0.5417 - val_accuracy: 0.8031\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.9276 - accuracy: 0.8144 - val_loss: 0.5193 - val_accuracy: 0.8107\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.6926 - accuracy: 0.8191 - val_loss: 0.4897 - val_accuracy: 0.8220\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.5475 - accuracy: 0.8242 - val_loss: 0.4937 - val_accuracy: 0.8219\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.4073 - accuracy: 0.8263 - val_loss: 0.4894 - val_accuracy: 0.8227\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.2210 - accuracy: 0.8318 - val_loss: 0.5308 - val_accuracy: 0.8006\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.0413 - accuracy: 0.8358 - val_loss: 0.5474 - val_accuracy: 0.8009\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.8999 - accuracy: 0.8394 - val_loss: 0.4353 - val_accuracy: 0.8432\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.6915 - accuracy: 0.8449 - val_loss: 0.4384 - val_accuracy: 0.8360\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.6831 - accuracy: 0.8444 - val_loss: 0.4335 - val_accuracy: 0.8380\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5131 - accuracy: 0.8486 - val_loss: 0.4590 - val_accuracy: 0.8305\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.4900 - accuracy: 0.8481 - val_loss: 0.4715 - val_accuracy: 0.8256\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.2296 - accuracy: 0.8546 - val_loss: 0.4579 - val_accuracy: 0.8333\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.1073 - accuracy: 0.8568 - val_loss: 0.4816 - val_accuracy: 0.8222\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.0333 - accuracy: 0.8587 - val_loss: 0.4235 - val_accuracy: 0.8505\n",
      "Epoch 28/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.8903 - accuracy: 0.8623 - val_loss: 0.4356 - val_accuracy: 0.8409\n",
      "Epoch 29/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.8204 - accuracy: 0.8643 - val_loss: 0.4619 - val_accuracy: 0.8316\n",
      "Epoch 30/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.6452 - accuracy: 0.8665 - val_loss: 0.4326 - val_accuracy: 0.8480\n",
      "Epoch 31/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.5757 - accuracy: 0.8690 - val_loss: 0.4386 - val_accuracy: 0.8459\n",
      "Epoch 32/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.5076 - accuracy: 0.8713 - val_loss: 0.4309 - val_accuracy: 0.8495\n",
      "2975/2975 [==============================] - 17s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "200 0 (41.38, 3.2180118085550897) 0.8776353831390618\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 26s 25ms/step - loss: 20.6192 - accuracy: 0.4062 - val_loss: 1.3641 - val_accuracy: 0.5395\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.3748 - accuracy: 0.5444 - val_loss: 1.1281 - val_accuracy: 0.6120\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.3940 - accuracy: 0.6000 - val_loss: 1.0263 - val_accuracy: 0.6376\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.8020 - accuracy: 0.6430 - val_loss: 0.9655 - val_accuracy: 0.6466\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.7212 - accuracy: 0.6716 - val_loss: 0.8367 - val_accuracy: 0.6973\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.6545 - accuracy: 0.7039 - val_loss: 0.7253 - val_accuracy: 0.7307\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.9068 - accuracy: 0.7264 - val_loss: 0.7866 - val_accuracy: 0.7119\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.2465 - accuracy: 0.7462 - val_loss: 0.6679 - val_accuracy: 0.7524\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.8651 - accuracy: 0.7580 - val_loss: 0.6149 - val_accuracy: 0.7761\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.3217 - accuracy: 0.7743 - val_loss: 0.5728 - val_accuracy: 0.7890\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.9611 - accuracy: 0.7839 - val_loss: 0.5499 - val_accuracy: 0.7969\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.6196 - accuracy: 0.7944 - val_loss: 0.5909 - val_accuracy: 0.7863\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.2283 - accuracy: 0.8051 - val_loss: 0.5112 - val_accuracy: 0.8111\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.0217 - accuracy: 0.8121 - val_loss: 0.5053 - val_accuracy: 0.8153\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.7573 - accuracy: 0.8182 - val_loss: 0.4883 - val_accuracy: 0.8201\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.5848 - accuracy: 0.8229 - val_loss: 0.5209 - val_accuracy: 0.8146\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.4208 - accuracy: 0.8260 - val_loss: 0.4833 - val_accuracy: 0.8215\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.1716 - accuracy: 0.8334 - val_loss: 0.4598 - val_accuracy: 0.8292\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.9801 - accuracy: 0.8376 - val_loss: 0.4689 - val_accuracy: 0.8301\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 5.9330 - accuracy: 0.8385 - val_loss: 0.4537 - val_accuracy: 0.8329\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.7992 - accuracy: 0.8404 - val_loss: 0.4458 - val_accuracy: 0.8392\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.6291 - accuracy: 0.8452 - val_loss: 0.4528 - val_accuracy: 0.8338\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5222 - accuracy: 0.8468 - val_loss: 0.4635 - val_accuracy: 0.8306\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.4026 - accuracy: 0.8507 - val_loss: 0.4282 - val_accuracy: 0.8465\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.1495 - accuracy: 0.8565 - val_loss: 0.4536 - val_accuracy: 0.8347\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 5.0888 - accuracy: 0.8569 - val_loss: 0.4501 - val_accuracy: 0.8396\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.0301 - accuracy: 0.8590 - val_loss: 0.4380 - val_accuracy: 0.8458\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744/744 [==============================] - 17s 22ms/step - loss: 4.9333 - accuracy: 0.8617 - val_loss: 0.4560 - val_accuracy: 0.8354\n",
      "Epoch 29/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.7410 - accuracy: 0.8656 - val_loss: 0.4599 - val_accuracy: 0.8363\n",
      "2975/2975 [==============================] - 17s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "200 1 (42.16, 2.8938555596297473) 0.8929059026062793\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 25ms/step - loss: 20.1904 - accuracy: 0.4169 - val_loss: 1.3832 - val_accuracy: 0.5024\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.7648 - accuracy: 0.5285 - val_loss: 1.2227 - val_accuracy: 0.5699\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.4353 - accuracy: 0.5993 - val_loss: 1.0039 - val_accuracy: 0.6415\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.8070 - accuracy: 0.6424 - val_loss: 0.9168 - val_accuracy: 0.6673\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.6249 - accuracy: 0.6746 - val_loss: 0.8370 - val_accuracy: 0.6940\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.6616 - accuracy: 0.7034 - val_loss: 0.8019 - val_accuracy: 0.6967\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.8591 - accuracy: 0.7267 - val_loss: 0.6973 - val_accuracy: 0.7396\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.3311 - accuracy: 0.7431 - val_loss: 0.6840 - val_accuracy: 0.7399\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.8169 - accuracy: 0.7590 - val_loss: 0.6170 - val_accuracy: 0.7724\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.4434 - accuracy: 0.7707 - val_loss: 0.6313 - val_accuracy: 0.7688\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.0516 - accuracy: 0.7825 - val_loss: 0.5938 - val_accuracy: 0.7811\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.7030 - accuracy: 0.7922 - val_loss: 0.5737 - val_accuracy: 0.7877\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.4154 - accuracy: 0.8011 - val_loss: 0.5152 - val_accuracy: 0.8091\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.1514 - accuracy: 0.8077 - val_loss: 0.5529 - val_accuracy: 0.7939\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.9722 - accuracy: 0.8128 - val_loss: 0.5551 - val_accuracy: 0.7945\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.6932 - accuracy: 0.8190 - val_loss: 0.5173 - val_accuracy: 0.8098\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 6.5046 - accuracy: 0.8245 - val_loss: 0.5203 - val_accuracy: 0.8089\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.3636 - accuracy: 0.8270 - val_loss: 0.4637 - val_accuracy: 0.8258\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.1912 - accuracy: 0.8321 - val_loss: 0.4927 - val_accuracy: 0.8189\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.0103 - accuracy: 0.8364 - val_loss: 0.5055 - val_accuracy: 0.8147\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.7763 - accuracy: 0.8417 - val_loss: 0.4525 - val_accuracy: 0.8322\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.6798 - accuracy: 0.8437 - val_loss: 0.4656 - val_accuracy: 0.8299\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5557 - accuracy: 0.8477 - val_loss: 0.4525 - val_accuracy: 0.8339\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3169 - accuracy: 0.8524 - val_loss: 0.4676 - val_accuracy: 0.8322\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.2735 - accuracy: 0.8527 - val_loss: 0.4165 - val_accuracy: 0.8515\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.1732 - accuracy: 0.8547 - val_loss: 0.4201 - val_accuracy: 0.8462\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.9937 - accuracy: 0.8604 - val_loss: 0.4361 - val_accuracy: 0.8406\n",
      "Epoch 28/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.8696 - accuracy: 0.8616 - val_loss: 0.4411 - val_accuracy: 0.8434\n",
      "Epoch 29/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.7311 - accuracy: 0.8659 - val_loss: 0.4612 - val_accuracy: 0.8343\n",
      "Epoch 30/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.6052 - accuracy: 0.8687 - val_loss: 0.4392 - val_accuracy: 0.8418\n",
      "2975/2975 [==============================] - 17s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "200 2 (40.04, 3.43487991056456) 0.8655932805889027\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 25ms/step - loss: 20.5197 - accuracy: 0.4068 - val_loss: 1.4177 - val_accuracy: 0.5120\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.1345 - accuracy: 0.5497 - val_loss: 1.2104 - val_accuracy: 0.5841\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.1825 - accuracy: 0.6076 - val_loss: 1.0323 - val_accuracy: 0.6362\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.7007 - accuracy: 0.6486 - val_loss: 1.0804 - val_accuracy: 0.6123\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.6553 - accuracy: 0.6750 - val_loss: 0.7974 - val_accuracy: 0.7091\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.5605 - accuracy: 0.7072 - val_loss: 0.7584 - val_accuracy: 0.7256\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.7606 - accuracy: 0.7318 - val_loss: 0.6931 - val_accuracy: 0.7497\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.1820 - accuracy: 0.7500 - val_loss: 0.6413 - val_accuracy: 0.7600\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.5399 - accuracy: 0.7696 - val_loss: 0.5538 - val_accuracy: 0.8004\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.0074 - accuracy: 0.7868 - val_loss: 0.5751 - val_accuracy: 0.7883\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.6466 - accuracy: 0.7963 - val_loss: 0.5882 - val_accuracy: 0.7845\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.3105 - accuracy: 0.8053 - val_loss: 0.5486 - val_accuracy: 0.8004\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.0174 - accuracy: 0.8139 - val_loss: 0.5805 - val_accuracy: 0.7911\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.8541 - accuracy: 0.8198 - val_loss: 0.4896 - val_accuracy: 0.8202\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.5815 - accuracy: 0.8237 - val_loss: 0.5113 - val_accuracy: 0.8136\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.4394 - accuracy: 0.8288 - val_loss: 0.4932 - val_accuracy: 0.8184\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.2070 - accuracy: 0.8349 - val_loss: 0.4701 - val_accuracy: 0.8264\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.0683 - accuracy: 0.8369 - val_loss: 0.4462 - val_accuracy: 0.8424\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.8657 - accuracy: 0.8421 - val_loss: 0.4818 - val_accuracy: 0.8265\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.7284 - accuracy: 0.8453 - val_loss: 0.4522 - val_accuracy: 0.8338\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5703 - accuracy: 0.8490 - val_loss: 0.4609 - val_accuracy: 0.8336\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.4262 - accuracy: 0.8510 - val_loss: 0.4233 - val_accuracy: 0.8494\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3943 - accuracy: 0.8533 - val_loss: 0.4673 - val_accuracy: 0.8333\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.1975 - accuracy: 0.8567 - val_loss: 0.4400 - val_accuracy: 0.8420\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.0662 - accuracy: 0.8582 - val_loss: 0.4538 - val_accuracy: 0.8348\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.9788 - accuracy: 0.8616 - val_loss: 0.4928 - val_accuracy: 0.8281\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.8697 - accuracy: 0.8619 - val_loss: 0.4312 - val_accuracy: 0.8451\n",
      "2975/2975 [==============================] - 17s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "210 0 (42.9, 3.0215889859476257) 0.8995036562627259\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 26s 28ms/step - loss: 20.2114 - accuracy: 0.4190 - val_loss: 1.3917 - val_accuracy: 0.5188\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.1291 - accuracy: 0.5517 - val_loss: 1.1971 - val_accuracy: 0.5782\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.1591 - accuracy: 0.6053 - val_loss: 0.9703 - val_accuracy: 0.6566\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.7538 - accuracy: 0.6440 - val_loss: 0.9957 - val_accuracy: 0.6399\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.6620 - accuracy: 0.6737 - val_loss: 0.8601 - val_accuracy: 0.6847\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.6909 - accuracy: 0.7034 - val_loss: 0.7488 - val_accuracy: 0.7305\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.8835 - accuracy: 0.7282 - val_loss: 0.6885 - val_accuracy: 0.7442\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.2034 - accuracy: 0.7486 - val_loss: 0.6678 - val_accuracy: 0.7558\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.6024 - accuracy: 0.7665 - val_loss: 0.6443 - val_accuracy: 0.7669\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.2017 - accuracy: 0.7782 - val_loss: 0.5747 - val_accuracy: 0.7900\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.8004 - accuracy: 0.7910 - val_loss: 0.5740 - val_accuracy: 0.7906\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.4774 - accuracy: 0.7997 - val_loss: 0.5171 - val_accuracy: 0.8090\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.1390 - accuracy: 0.8081 - val_loss: 0.5534 - val_accuracy: 0.8010\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.8869 - accuracy: 0.8162 - val_loss: 0.4757 - val_accuracy: 0.8279\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.6888 - accuracy: 0.8208 - val_loss: 0.5152 - val_accuracy: 0.8140\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.4754 - accuracy: 0.8273 - val_loss: 0.4688 - val_accuracy: 0.8289\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.2904 - accuracy: 0.8306 - val_loss: 0.4729 - val_accuracy: 0.8281\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.0981 - accuracy: 0.8339 - val_loss: 0.4547 - val_accuracy: 0.8354\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.9266 - accuracy: 0.8391 - val_loss: 0.4786 - val_accuracy: 0.8281\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.7931 - accuracy: 0.8419 - val_loss: 0.4319 - val_accuracy: 0.8464\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5951 - accuracy: 0.8471 - val_loss: 0.4856 - val_accuracy: 0.8274\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5015 - accuracy: 0.8490 - val_loss: 0.4492 - val_accuracy: 0.8372\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3475 - accuracy: 0.8528 - val_loss: 0.4265 - val_accuracy: 0.8435\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.1753 - accuracy: 0.8556 - val_loss: 0.4451 - val_accuracy: 0.8395\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.1526 - accuracy: 0.8560 - val_loss: 0.5018 - val_accuracy: 0.8190\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.9019 - accuracy: 0.8622 - val_loss: 0.4547 - val_accuracy: 0.8360\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.8851 - accuracy: 0.8626 - val_loss: 0.4462 - val_accuracy: 0.8395\n",
      "Epoch 28/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.6537 - accuracy: 0.8675 - val_loss: 0.4330 - val_accuracy: 0.8461\n",
      "2975/2975 [==============================] - 17s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "210 1 (45.14, 2.6684077649414824) 0.9124133857528385\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 25ms/step - loss: 20.5301 - accuracy: 0.4067 - val_loss: 1.4195 - val_accuracy: 0.5151\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.2987 - accuracy: 0.5450 - val_loss: 1.1754 - val_accuracy: 0.5887\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.1795 - accuracy: 0.6070 - val_loss: 1.0420 - val_accuracy: 0.6260\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.6157 - accuracy: 0.6473 - val_loss: 0.9203 - val_accuracy: 0.6683\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.2901 - accuracy: 0.6846 - val_loss: 0.7530 - val_accuracy: 0.7232\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.3176 - accuracy: 0.7137 - val_loss: 0.7406 - val_accuracy: 0.7263\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.4892 - accuracy: 0.7395 - val_loss: 0.6782 - val_accuracy: 0.7532\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.8612 - accuracy: 0.7581 - val_loss: 0.6346 - val_accuracy: 0.7624\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.3523 - accuracy: 0.7762 - val_loss: 0.6044 - val_accuracy: 0.7790\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.9201 - accuracy: 0.7863 - val_loss: 0.5641 - val_accuracy: 0.7927\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.5580 - accuracy: 0.7971 - val_loss: 0.5137 - val_accuracy: 0.8127\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.2275 - accuracy: 0.8069 - val_loss: 0.5689 - val_accuracy: 0.7860\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.9836 - accuracy: 0.8134 - val_loss: 0.5258 - val_accuracy: 0.8066\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.8141 - accuracy: 0.8162 - val_loss: 0.5019 - val_accuracy: 0.8138\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.5522 - accuracy: 0.8226 - val_loss: 0.5213 - val_accuracy: 0.8065\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.3295 - accuracy: 0.8283 - val_loss: 0.4642 - val_accuracy: 0.8315\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.2524 - accuracy: 0.8300 - val_loss: 0.5256 - val_accuracy: 0.8138\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.0748 - accuracy: 0.8360 - val_loss: 0.4616 - val_accuracy: 0.8282\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.8429 - accuracy: 0.8398 - val_loss: 0.4623 - val_accuracy: 0.8275\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744/744 [==============================] - 16s 22ms/step - loss: 5.7264 - accuracy: 0.8438 - val_loss: 0.4341 - val_accuracy: 0.8374\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5559 - accuracy: 0.8482 - val_loss: 0.4446 - val_accuracy: 0.8349\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3933 - accuracy: 0.8511 - val_loss: 0.4696 - val_accuracy: 0.8280\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3762 - accuracy: 0.8517 - val_loss: 0.4745 - val_accuracy: 0.8275\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.2052 - accuracy: 0.8554 - val_loss: 0.4584 - val_accuracy: 0.8326\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.0829 - accuracy: 0.8582 - val_loss: 0.4548 - val_accuracy: 0.8342\n",
      "2975/2975 [==============================] - 17s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "210 2 (45.34, 2.642801543816713) 0.9131307683949108\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 24ms/step - loss: 20.5118 - accuracy: 0.4053 - val_loss: 1.4396 - val_accuracy: 0.4901\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.3778 - accuracy: 0.5431 - val_loss: 1.2091 - val_accuracy: 0.5803\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.3645 - accuracy: 0.6023 - val_loss: 0.9793 - val_accuracy: 0.6507\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.6390 - accuracy: 0.6483 - val_loss: 0.9135 - val_accuracy: 0.6710\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.5354 - accuracy: 0.6771 - val_loss: 0.8433 - val_accuracy: 0.6936\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.5741 - accuracy: 0.7050 - val_loss: 0.7658 - val_accuracy: 0.7223\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.8566 - accuracy: 0.7277 - val_loss: 0.7420 - val_accuracy: 0.7202\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.2529 - accuracy: 0.7458 - val_loss: 0.6760 - val_accuracy: 0.7516\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.7276 - accuracy: 0.7615 - val_loss: 0.6398 - val_accuracy: 0.7660\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.2496 - accuracy: 0.7776 - val_loss: 0.6632 - val_accuracy: 0.7523\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.9169 - accuracy: 0.7869 - val_loss: 0.5709 - val_accuracy: 0.7889\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.5301 - accuracy: 0.7979 - val_loss: 0.5677 - val_accuracy: 0.7912\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.2228 - accuracy: 0.8067 - val_loss: 0.5658 - val_accuracy: 0.7969\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.9309 - accuracy: 0.8146 - val_loss: 0.5456 - val_accuracy: 0.8023\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.7442 - accuracy: 0.8195 - val_loss: 0.4833 - val_accuracy: 0.8211\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.4957 - accuracy: 0.8253 - val_loss: 0.5027 - val_accuracy: 0.8187\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.2645 - accuracy: 0.8317 - val_loss: 0.4781 - val_accuracy: 0.8262\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.0130 - accuracy: 0.8374 - val_loss: 0.4720 - val_accuracy: 0.8291\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.9231 - accuracy: 0.8396 - val_loss: 0.4520 - val_accuracy: 0.8346\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.7249 - accuracy: 0.8441 - val_loss: 0.4775 - val_accuracy: 0.8238\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5245 - accuracy: 0.8501 - val_loss: 0.4334 - val_accuracy: 0.8452\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.4422 - accuracy: 0.8505 - val_loss: 0.4511 - val_accuracy: 0.8379\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.2607 - accuracy: 0.8559 - val_loss: 0.4665 - val_accuracy: 0.8322\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.2038 - accuracy: 0.8561 - val_loss: 0.4388 - val_accuracy: 0.8436\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.0402 - accuracy: 0.8607 - val_loss: 0.4953 - val_accuracy: 0.8261\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.9326 - accuracy: 0.8626 - val_loss: 0.4595 - val_accuracy: 0.8374\n",
      "2975/2975 [==============================] - 17s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "220 0 (42.8, 3.32264954516723) 0.8955112097554165\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 24ms/step - loss: 20.4740 - accuracy: 0.4098 - val_loss: 1.4073 - val_accuracy: 0.5116\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.0658 - accuracy: 0.5502 - val_loss: 1.1784 - val_accuracy: 0.5871\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 13.9630 - accuracy: 0.6137 - val_loss: 0.9883 - val_accuracy: 0.6520\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.5482 - accuracy: 0.6498 - val_loss: 0.9259 - val_accuracy: 0.6655\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.4094 - accuracy: 0.6807 - val_loss: 0.8296 - val_accuracy: 0.6929\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.4328 - accuracy: 0.7103 - val_loss: 0.7539 - val_accuracy: 0.7251\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.5245 - accuracy: 0.7398 - val_loss: 0.6865 - val_accuracy: 0.7478\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.8101 - accuracy: 0.7636 - val_loss: 0.5936 - val_accuracy: 0.7813\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.2456 - accuracy: 0.7778 - val_loss: 0.5916 - val_accuracy: 0.7867\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.8874 - accuracy: 0.7906 - val_loss: 0.5964 - val_accuracy: 0.7778\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.4619 - accuracy: 0.8002 - val_loss: 0.5839 - val_accuracy: 0.7812\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.1953 - accuracy: 0.8076 - val_loss: 0.5176 - val_accuracy: 0.8097\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.0817 - accuracy: 0.8108 - val_loss: 0.5230 - val_accuracy: 0.8048\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.6579 - accuracy: 0.8216 - val_loss: 0.4742 - val_accuracy: 0.8289\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.4156 - accuracy: 0.8278 - val_loss: 0.4583 - val_accuracy: 0.8309\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.3275 - accuracy: 0.8283 - val_loss: 0.4622 - val_accuracy: 0.8303\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.1302 - accuracy: 0.8351 - val_loss: 0.4647 - val_accuracy: 0.8328\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.0014 - accuracy: 0.8370 - val_loss: 0.5181 - val_accuracy: 0.8077\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.7122 - accuracy: 0.8442 - val_loss: 0.4591 - val_accuracy: 0.8291\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.6589 - accuracy: 0.8438 - val_loss: 0.4352 - val_accuracy: 0.8404\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.4789 - accuracy: 0.8498 - val_loss: 0.4435 - val_accuracy: 0.8385\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.2799 - accuracy: 0.8538 - val_loss: 0.4130 - val_accuracy: 0.8473\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.1520 - accuracy: 0.8566 - val_loss: 0.4594 - val_accuracy: 0.8327\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.1127 - accuracy: 0.8572 - val_loss: 0.4579 - val_accuracy: 0.8380\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.0337 - accuracy: 0.8598 - val_loss: 0.4266 - val_accuracy: 0.8438\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.7956 - accuracy: 0.8646 - val_loss: 0.4343 - val_accuracy: 0.8462\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.8204 - accuracy: 0.8635 - val_loss: 0.4080 - val_accuracy: 0.8550\n",
      "Epoch 28/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.6505 - accuracy: 0.8673 - val_loss: 0.4503 - val_accuracy: 0.8390\n",
      "Epoch 29/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.5788 - accuracy: 0.8684 - val_loss: 0.4310 - val_accuracy: 0.8480\n",
      "Epoch 30/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.4132 - accuracy: 0.8719 - val_loss: 0.4255 - val_accuracy: 0.8514\n",
      "Epoch 31/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.3571 - accuracy: 0.8750 - val_loss: 0.4396 - val_accuracy: 0.8443\n",
      "Epoch 32/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.1557 - accuracy: 0.8792 - val_loss: 0.4360 - val_accuracy: 0.8474\n",
      "2975/2975 [==============================] - 17s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "220 1 (42.24, 2.6725268941584104) 0.8965272673888989\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 27s 24ms/step - loss: 20.4012 - accuracy: 0.4092 - val_loss: 1.4229 - val_accuracy: 0.4950\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.2831 - accuracy: 0.5422 - val_loss: 1.2242 - val_accuracy: 0.5597\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.1482 - accuracy: 0.6068 - val_loss: 1.0248 - val_accuracy: 0.6342\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.6561 - accuracy: 0.6466 - val_loss: 0.9338 - val_accuracy: 0.6624\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.6658 - accuracy: 0.6741 - val_loss: 0.8333 - val_accuracy: 0.6978\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.6987 - accuracy: 0.7015 - val_loss: 0.8290 - val_accuracy: 0.7025\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.8805 - accuracy: 0.7288 - val_loss: 0.7188 - val_accuracy: 0.7370\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.2528 - accuracy: 0.7487 - val_loss: 0.7545 - val_accuracy: 0.7249\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.7118 - accuracy: 0.7645 - val_loss: 0.6235 - val_accuracy: 0.7724\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.2386 - accuracy: 0.7782 - val_loss: 0.6356 - val_accuracy: 0.7654\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.8816 - accuracy: 0.7886 - val_loss: 0.6227 - val_accuracy: 0.7735\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.4931 - accuracy: 0.7981 - val_loss: 0.5887 - val_accuracy: 0.7826\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.3252 - accuracy: 0.8038 - val_loss: 0.5145 - val_accuracy: 0.8082\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.0192 - accuracy: 0.8121 - val_loss: 0.5794 - val_accuracy: 0.7886\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.8388 - accuracy: 0.8179 - val_loss: 0.4861 - val_accuracy: 0.8270\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.6027 - accuracy: 0.8236 - val_loss: 0.4982 - val_accuracy: 0.8175\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.3478 - accuracy: 0.8306 - val_loss: 0.4732 - val_accuracy: 0.8249\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.2168 - accuracy: 0.8339 - val_loss: 0.4581 - val_accuracy: 0.8292\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.0194 - accuracy: 0.8375 - val_loss: 0.5079 - val_accuracy: 0.8158\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.8886 - accuracy: 0.8408 - val_loss: 0.4689 - val_accuracy: 0.8259\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.7351 - accuracy: 0.8456 - val_loss: 0.4517 - val_accuracy: 0.8329\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5855 - accuracy: 0.8482 - val_loss: 0.4248 - val_accuracy: 0.8457\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.4793 - accuracy: 0.8494 - val_loss: 0.4571 - val_accuracy: 0.8311\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3367 - accuracy: 0.8536 - val_loss: 0.4466 - val_accuracy: 0.8380\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.1968 - accuracy: 0.8564 - val_loss: 0.4387 - val_accuracy: 0.8404\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.1174 - accuracy: 0.8580 - val_loss: 0.4391 - val_accuracy: 0.8395\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.9868 - accuracy: 0.8616 - val_loss: 0.4540 - val_accuracy: 0.8364\n",
      "2975/2975 [==============================] - 17s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "220 2 (40.62, 3.19931242613159) 0.8803662390074279\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 24ms/step - loss: 20.3032 - accuracy: 0.4119 - val_loss: 1.4987 - val_accuracy: 0.4623\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.3978 - accuracy: 0.5426 - val_loss: 1.1774 - val_accuracy: 0.5895\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.3568 - accuracy: 0.6002 - val_loss: 1.0015 - val_accuracy: 0.6453\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.8572 - accuracy: 0.6416 - val_loss: 0.9096 - val_accuracy: 0.6724\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.6337 - accuracy: 0.6754 - val_loss: 0.8008 - val_accuracy: 0.7120\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.7934 - accuracy: 0.6998 - val_loss: 0.7274 - val_accuracy: 0.7324\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.9759 - accuracy: 0.7250 - val_loss: 0.7232 - val_accuracy: 0.7373\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.3751 - accuracy: 0.7440 - val_loss: 0.6456 - val_accuracy: 0.7641\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.7882 - accuracy: 0.7605 - val_loss: 0.6060 - val_accuracy: 0.7800\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.3886 - accuracy: 0.7728 - val_loss: 0.5733 - val_accuracy: 0.7894\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.0253 - accuracy: 0.7818 - val_loss: 0.5856 - val_accuracy: 0.7887\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.7012 - accuracy: 0.7921 - val_loss: 0.5696 - val_accuracy: 0.7912\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.4166 - accuracy: 0.8020 - val_loss: 0.5757 - val_accuracy: 0.7882\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.1750 - accuracy: 0.8058 - val_loss: 0.5377 - val_accuracy: 0.8016\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.9043 - accuracy: 0.8135 - val_loss: 0.5363 - val_accuracy: 0.8027\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744/744 [==============================] - 16s 22ms/step - loss: 6.7018 - accuracy: 0.8197 - val_loss: 0.5471 - val_accuracy: 0.7912\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.5312 - accuracy: 0.8237 - val_loss: 0.5136 - val_accuracy: 0.8089\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.3412 - accuracy: 0.8285 - val_loss: 0.5252 - val_accuracy: 0.8127\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.1053 - accuracy: 0.8332 - val_loss: 0.5091 - val_accuracy: 0.8154\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.9417 - accuracy: 0.8377 - val_loss: 0.4905 - val_accuracy: 0.8185\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.8194 - accuracy: 0.8409 - val_loss: 0.4699 - val_accuracy: 0.8238\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.6938 - accuracy: 0.8438 - val_loss: 0.4787 - val_accuracy: 0.8238\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5398 - accuracy: 0.8470 - val_loss: 0.4649 - val_accuracy: 0.8288\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3645 - accuracy: 0.8516 - val_loss: 0.5374 - val_accuracy: 0.8053\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3577 - accuracy: 0.8514 - val_loss: 0.4705 - val_accuracy: 0.8255\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.1055 - accuracy: 0.8575 - val_loss: 0.4865 - val_accuracy: 0.8247\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.0335 - accuracy: 0.8573 - val_loss: 0.5457 - val_accuracy: 0.8076\n",
      "Epoch 28/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.8433 - accuracy: 0.8625 - val_loss: 0.4251 - val_accuracy: 0.8457\n",
      "Epoch 29/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.6973 - accuracy: 0.8657 - val_loss: 0.4821 - val_accuracy: 0.8260\n",
      "Epoch 30/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.6772 - accuracy: 0.8667 - val_loss: 0.4261 - val_accuracy: 0.8491\n",
      "Epoch 31/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.5514 - accuracy: 0.8697 - val_loss: 0.4552 - val_accuracy: 0.8403\n",
      "Epoch 32/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.4782 - accuracy: 0.8702 - val_loss: 0.4338 - val_accuracy: 0.8466\n",
      "Epoch 33/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.3010 - accuracy: 0.8756 - val_loss: 0.4416 - val_accuracy: 0.8465\n",
      "2975/2975 [==============================] - 17s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "230 0 (43.02, 2.7675982367388516) 0.8884033902405919\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 24ms/step - loss: 20.5447 - accuracy: 0.4044 - val_loss: 1.4954 - val_accuracy: 0.4751\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.6007 - accuracy: 0.5380 - val_loss: 1.2598 - val_accuracy: 0.5584\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.4170 - accuracy: 0.6024 - val_loss: 1.0535 - val_accuracy: 0.6275\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.9640 - accuracy: 0.6381 - val_loss: 1.0605 - val_accuracy: 0.6301\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.8344 - accuracy: 0.6691 - val_loss: 0.8310 - val_accuracy: 0.6973\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.7108 - accuracy: 0.7017 - val_loss: 0.8874 - val_accuracy: 0.6650\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.9552 - accuracy: 0.7237 - val_loss: 0.7161 - val_accuracy: 0.7384\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.3536 - accuracy: 0.7430 - val_loss: 0.6318 - val_accuracy: 0.7656\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.8306 - accuracy: 0.7575 - val_loss: 0.6130 - val_accuracy: 0.7722\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.4000 - accuracy: 0.7704 - val_loss: 0.6315 - val_accuracy: 0.7682\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.0851 - accuracy: 0.7807 - val_loss: 0.5603 - val_accuracy: 0.7964\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.7063 - accuracy: 0.7916 - val_loss: 0.5713 - val_accuracy: 0.7877\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.4070 - accuracy: 0.8006 - val_loss: 0.5249 - val_accuracy: 0.8087\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.1300 - accuracy: 0.8087 - val_loss: 0.5394 - val_accuracy: 0.8042\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.9194 - accuracy: 0.8151 - val_loss: 0.5417 - val_accuracy: 0.7984\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.6775 - accuracy: 0.8197 - val_loss: 0.5522 - val_accuracy: 0.7971\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.5005 - accuracy: 0.8257 - val_loss: 0.4782 - val_accuracy: 0.8227\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.3595 - accuracy: 0.8289 - val_loss: 0.4894 - val_accuracy: 0.8217\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.1776 - accuracy: 0.8322 - val_loss: 0.4871 - val_accuracy: 0.8197\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.9842 - accuracy: 0.8370 - val_loss: 0.4533 - val_accuracy: 0.8367\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.8138 - accuracy: 0.8426 - val_loss: 0.4659 - val_accuracy: 0.8269\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.7162 - accuracy: 0.8440 - val_loss: 0.4320 - val_accuracy: 0.8421\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5520 - accuracy: 0.8474 - val_loss: 0.4459 - val_accuracy: 0.8352\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.4330 - accuracy: 0.8504 - val_loss: 0.5023 - val_accuracy: 0.8193\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.2482 - accuracy: 0.8545 - val_loss: 0.4713 - val_accuracy: 0.8269\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.1615 - accuracy: 0.8554 - val_loss: 0.4512 - val_accuracy: 0.8409\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.0596 - accuracy: 0.8571 - val_loss: 0.4406 - val_accuracy: 0.8421\n",
      "2975/2975 [==============================] - 17s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "230 1 (39.78, 3.20181198698487) 0.8707416679873016\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 24ms/step - loss: 20.1825 - accuracy: 0.4209 - val_loss: 1.4505 - val_accuracy: 0.4743\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.5859 - accuracy: 0.5336 - val_loss: 1.1352 - val_accuracy: 0.6025\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.3744 - accuracy: 0.5997 - val_loss: 1.0663 - val_accuracy: 0.6225\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.8120 - accuracy: 0.6399 - val_loss: 1.0513 - val_accuracy: 0.6257\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.5863 - accuracy: 0.6773 - val_loss: 0.7947 - val_accuracy: 0.7128\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.3694 - accuracy: 0.7120 - val_loss: 0.7543 - val_accuracy: 0.7203\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.5111 - accuracy: 0.7386 - val_loss: 0.6982 - val_accuracy: 0.7384\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.9118 - accuracy: 0.7560 - val_loss: 0.6331 - val_accuracy: 0.7705\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.5007 - accuracy: 0.7700 - val_loss: 0.6175 - val_accuracy: 0.7764\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.9759 - accuracy: 0.7848 - val_loss: 0.6273 - val_accuracy: 0.7694\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.6512 - accuracy: 0.7936 - val_loss: 0.5770 - val_accuracy: 0.7860\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.3489 - accuracy: 0.8028 - val_loss: 0.5639 - val_accuracy: 0.7862\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.0632 - accuracy: 0.8097 - val_loss: 0.4916 - val_accuracy: 0.8216\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.8796 - accuracy: 0.8158 - val_loss: 0.4913 - val_accuracy: 0.8158\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.6263 - accuracy: 0.8215 - val_loss: 0.4651 - val_accuracy: 0.8299\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.4220 - accuracy: 0.8279 - val_loss: 0.4750 - val_accuracy: 0.8261\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.2788 - accuracy: 0.8322 - val_loss: 0.4773 - val_accuracy: 0.8207\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.0084 - accuracy: 0.8378 - val_loss: 0.4694 - val_accuracy: 0.8264\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.9656 - accuracy: 0.8380 - val_loss: 0.4722 - val_accuracy: 0.8280\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.7600 - accuracy: 0.8439 - val_loss: 0.4415 - val_accuracy: 0.8380\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5779 - accuracy: 0.8461 - val_loss: 0.4495 - val_accuracy: 0.8334\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5086 - accuracy: 0.8490 - val_loss: 0.4356 - val_accuracy: 0.8391\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3591 - accuracy: 0.8522 - val_loss: 0.4573 - val_accuracy: 0.8316\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.2069 - accuracy: 0.8557 - val_loss: 0.4355 - val_accuracy: 0.8417\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.0471 - accuracy: 0.8588 - val_loss: 0.4413 - val_accuracy: 0.8438\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.9848 - accuracy: 0.8613 - val_loss: 0.4242 - val_accuracy: 0.8475\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.8535 - accuracy: 0.8634 - val_loss: 0.4464 - val_accuracy: 0.8392\n",
      "Epoch 28/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.6824 - accuracy: 0.8670 - val_loss: 0.4426 - val_accuracy: 0.8379\n",
      "Epoch 29/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.6020 - accuracy: 0.8689 - val_loss: 0.4230 - val_accuracy: 0.8485\n",
      "Epoch 30/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.4689 - accuracy: 0.8719 - val_loss: 0.4130 - val_accuracy: 0.8517\n",
      "Epoch 31/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.3454 - accuracy: 0.8750 - val_loss: 0.4593 - val_accuracy: 0.8347\n",
      "Epoch 32/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.2462 - accuracy: 0.8771 - val_loss: 0.4153 - val_accuracy: 0.8527\n",
      "Epoch 33/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.1862 - accuracy: 0.8771 - val_loss: 0.4393 - val_accuracy: 0.8490\n",
      "Epoch 34/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.3300 - accuracy: 0.8747 - val_loss: 0.4557 - val_accuracy: 0.8385\n",
      "Epoch 35/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 3.8281 - accuracy: 0.8848 - val_loss: 0.4440 - val_accuracy: 0.8457\n",
      "2975/2975 [==============================] - 17s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "230 2 (44.42, 2.919520508576708) 0.9089763137318547\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 25ms/step - loss: 20.7112 - accuracy: 0.4034 - val_loss: 1.4430 - val_accuracy: 0.4923\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.5441 - accuracy: 0.5331 - val_loss: 1.2455 - val_accuracy: 0.5619\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.2267 - accuracy: 0.6051 - val_loss: 1.0170 - val_accuracy: 0.6376\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.8002 - accuracy: 0.6437 - val_loss: 0.9038 - val_accuracy: 0.6709\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.6521 - accuracy: 0.6757 - val_loss: 0.8107 - val_accuracy: 0.7031\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.6563 - accuracy: 0.7038 - val_loss: 0.7447 - val_accuracy: 0.7281\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.9565 - accuracy: 0.7273 - val_loss: 0.7633 - val_accuracy: 0.7179\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.2534 - accuracy: 0.7458 - val_loss: 0.6465 - val_accuracy: 0.7648\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.7667 - accuracy: 0.7598 - val_loss: 0.6219 - val_accuracy: 0.7724\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.3014 - accuracy: 0.7747 - val_loss: 0.5973 - val_accuracy: 0.7821\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.9139 - accuracy: 0.7859 - val_loss: 0.5674 - val_accuracy: 0.7922\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.6576 - accuracy: 0.7943 - val_loss: 0.5675 - val_accuracy: 0.7907\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.3165 - accuracy: 0.8047 - val_loss: 0.5236 - val_accuracy: 0.8089\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.9869 - accuracy: 0.8121 - val_loss: 0.5244 - val_accuracy: 0.8135\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.8118 - accuracy: 0.8166 - val_loss: 0.5141 - val_accuracy: 0.8157\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.6378 - accuracy: 0.8207 - val_loss: 0.4942 - val_accuracy: 0.8221\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.4357 - accuracy: 0.8260 - val_loss: 0.4802 - val_accuracy: 0.8306\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.1791 - accuracy: 0.8340 - val_loss: 0.5131 - val_accuracy: 0.8131\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.1006 - accuracy: 0.8343 - val_loss: 0.4473 - val_accuracy: 0.8410\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.9284 - accuracy: 0.8404 - val_loss: 0.4543 - val_accuracy: 0.8307\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.7064 - accuracy: 0.8441 - val_loss: 0.4483 - val_accuracy: 0.8369\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.5814 - accuracy: 0.8462 - val_loss: 0.4615 - val_accuracy: 0.8329\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.4762 - accuracy: 0.8501 - val_loss: 0.4510 - val_accuracy: 0.8390\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.2890 - accuracy: 0.8534 - val_loss: 0.4515 - val_accuracy: 0.8373\n",
      "2975/2975 [==============================] - 17s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "240 0 (45.54, 2.6848463643195677) 0.9170102377935148\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 24ms/step - loss: 20.4382 - accuracy: 0.4087 - val_loss: 1.3669 - val_accuracy: 0.5254\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 16.1671 - accuracy: 0.5507 - val_loss: 1.1599 - val_accuracy: 0.5907\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744/744 [==============================] - 16s 22ms/step - loss: 13.9699 - accuracy: 0.6135 - val_loss: 0.9879 - val_accuracy: 0.6503\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.4566 - accuracy: 0.6544 - val_loss: 0.9842 - val_accuracy: 0.6391\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.1366 - accuracy: 0.6910 - val_loss: 0.8249 - val_accuracy: 0.6998\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.2474 - accuracy: 0.7163 - val_loss: 0.7304 - val_accuracy: 0.7310\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.6674 - accuracy: 0.7334 - val_loss: 0.7135 - val_accuracy: 0.7343\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.9607 - accuracy: 0.7561 - val_loss: 0.6137 - val_accuracy: 0.7748\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.5428 - accuracy: 0.7693 - val_loss: 0.6167 - val_accuracy: 0.7732\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.1365 - accuracy: 0.7794 - val_loss: 0.5735 - val_accuracy: 0.7879\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.7312 - accuracy: 0.7919 - val_loss: 0.5307 - val_accuracy: 0.8054\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.4767 - accuracy: 0.7991 - val_loss: 0.5147 - val_accuracy: 0.8085\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.2394 - accuracy: 0.8055 - val_loss: 0.5711 - val_accuracy: 0.7933\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.9278 - accuracy: 0.8142 - val_loss: 0.5007 - val_accuracy: 0.8148\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.7304 - accuracy: 0.8199 - val_loss: 0.5131 - val_accuracy: 0.8069\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.5194 - accuracy: 0.8237 - val_loss: 0.4696 - val_accuracy: 0.8280\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.3533 - accuracy: 0.8279 - val_loss: 0.4851 - val_accuracy: 0.8234\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.1345 - accuracy: 0.8346 - val_loss: 0.4444 - val_accuracy: 0.8334\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.9830 - accuracy: 0.8372 - val_loss: 0.4657 - val_accuracy: 0.8270\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.8612 - accuracy: 0.8411 - val_loss: 0.4618 - val_accuracy: 0.8310\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.6817 - accuracy: 0.8439 - val_loss: 0.4288 - val_accuracy: 0.8425\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5095 - accuracy: 0.8483 - val_loss: 0.4337 - val_accuracy: 0.8404\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3750 - accuracy: 0.8512 - val_loss: 0.4546 - val_accuracy: 0.8356\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.2208 - accuracy: 0.8556 - val_loss: 0.4474 - val_accuracy: 0.8401\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.1337 - accuracy: 0.8561 - val_loss: 0.4399 - val_accuracy: 0.8417\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.0121 - accuracy: 0.8600 - val_loss: 0.4253 - val_accuracy: 0.8512\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.8488 - accuracy: 0.8633 - val_loss: 0.4476 - val_accuracy: 0.8355\n",
      "Epoch 28/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 4.8315 - accuracy: 0.8625 - val_loss: 0.4554 - val_accuracy: 0.8362\n",
      "Epoch 29/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.6241 - accuracy: 0.8683 - val_loss: 0.4451 - val_accuracy: 0.8429\n",
      "Epoch 30/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.4825 - accuracy: 0.8712 - val_loss: 0.4405 - val_accuracy: 0.8469\n",
      "Epoch 31/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 4.4122 - accuracy: 0.8730 - val_loss: 0.4435 - val_accuracy: 0.8477\n",
      "2975/2975 [==============================] - 18s 5ms/step\n",
      "372/372 [==============================] - 2s 6ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "240 1 (42.26, 3.279085238294363) 0.896212943341477\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 25s 25ms/step - loss: 20.4141 - accuracy: 0.4105 - val_loss: 1.4534 - val_accuracy: 0.4883\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 16.5914 - accuracy: 0.5363 - val_loss: 1.2145 - val_accuracy: 0.5746\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 14.4882 - accuracy: 0.6014 - val_loss: 1.1108 - val_accuracy: 0.6053\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 13.0100 - accuracy: 0.6383 - val_loss: 0.9697 - val_accuracy: 0.6485\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 11.8625 - accuracy: 0.6680 - val_loss: 0.9210 - val_accuracy: 0.6685\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 10.9399 - accuracy: 0.6934 - val_loss: 0.7596 - val_accuracy: 0.7226\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 10.1922 - accuracy: 0.7166 - val_loss: 0.7110 - val_accuracy: 0.7416\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 9.4794 - accuracy: 0.7403 - val_loss: 0.6838 - val_accuracy: 0.7455\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.8210 - accuracy: 0.7600 - val_loss: 0.6579 - val_accuracy: 0.7515\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 8.3773 - accuracy: 0.7728 - val_loss: 0.6561 - val_accuracy: 0.7531\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 8.0158 - accuracy: 0.7842 - val_loss: 0.5808 - val_accuracy: 0.7846\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 7.6646 - accuracy: 0.7938 - val_loss: 0.5523 - val_accuracy: 0.7991\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 7.3492 - accuracy: 0.8033 - val_loss: 0.5299 - val_accuracy: 0.8069\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 7.0250 - accuracy: 0.8112 - val_loss: 0.5242 - val_accuracy: 0.8051\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.8468 - accuracy: 0.8164 - val_loss: 0.5904 - val_accuracy: 0.7842\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.7053 - accuracy: 0.8211 - val_loss: 0.4804 - val_accuracy: 0.8255\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.4458 - accuracy: 0.8270 - val_loss: 0.4641 - val_accuracy: 0.8316\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.2055 - accuracy: 0.8326 - val_loss: 0.5146 - val_accuracy: 0.8135\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.0820 - accuracy: 0.8359 - val_loss: 0.4515 - val_accuracy: 0.8364\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.9212 - accuracy: 0.8393 - val_loss: 0.4843 - val_accuracy: 0.8218\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.7539 - accuracy: 0.8420 - val_loss: 0.4740 - val_accuracy: 0.8263\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5952 - accuracy: 0.8463 - val_loss: 0.4019 - val_accuracy: 0.8553\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.4547 - accuracy: 0.8499 - val_loss: 0.4753 - val_accuracy: 0.8357\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.3214 - accuracy: 0.8525 - val_loss: 0.4308 - val_accuracy: 0.8427\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.2091 - accuracy: 0.8560 - val_loss: 0.4202 - val_accuracy: 0.8530\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.0939 - accuracy: 0.8578 - val_loss: 0.4418 - val_accuracy: 0.8432\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 4.9458 - accuracy: 0.8614 - val_loss: 0.4398 - val_accuracy: 0.8443\n",
      "2975/2975 [==============================] - 18s 5ms/step\n",
      "372/372 [==============================] - 2s 6ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "240 2 (42.2, 2.764054992217051) 0.8885568425143338\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 25ms/step - loss: 20.3948 - accuracy: 0.4104 - val_loss: 1.4072 - val_accuracy: 0.5105\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 16.2229 - accuracy: 0.5462 - val_loss: 1.2061 - val_accuracy: 0.5792\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 14.3768 - accuracy: 0.5996 - val_loss: 1.0159 - val_accuracy: 0.6394\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 12.9552 - accuracy: 0.6402 - val_loss: 0.9931 - val_accuracy: 0.6494\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 11.9416 - accuracy: 0.6688 - val_loss: 0.8769 - val_accuracy: 0.6754\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 10.9543 - accuracy: 0.6930 - val_loss: 0.8128 - val_accuracy: 0.7030\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 10.1093 - accuracy: 0.7196 - val_loss: 0.8035 - val_accuracy: 0.7074\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 9.3177 - accuracy: 0.7441 - val_loss: 0.6644 - val_accuracy: 0.7535\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 8.6824 - accuracy: 0.7661 - val_loss: 0.7051 - val_accuracy: 0.7371\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 8.2678 - accuracy: 0.7780 - val_loss: 0.6018 - val_accuracy: 0.7832\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.8266 - accuracy: 0.7907 - val_loss: 0.5406 - val_accuracy: 0.8059\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.5056 - accuracy: 0.8014 - val_loss: 0.5329 - val_accuracy: 0.8025\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 7.1871 - accuracy: 0.8092 - val_loss: 0.5672 - val_accuracy: 0.7943\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.9005 - accuracy: 0.8172 - val_loss: 0.5090 - val_accuracy: 0.8112\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.6634 - accuracy: 0.8228 - val_loss: 0.4956 - val_accuracy: 0.8163\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.4968 - accuracy: 0.8265 - val_loss: 0.4734 - val_accuracy: 0.8221\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.3145 - accuracy: 0.8322 - val_loss: 0.4821 - val_accuracy: 0.8232\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.1343 - accuracy: 0.8356 - val_loss: 0.4850 - val_accuracy: 0.8209\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 5.9700 - accuracy: 0.8377 - val_loss: 0.4520 - val_accuracy: 0.8336\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.8479 - accuracy: 0.8422 - val_loss: 0.4486 - val_accuracy: 0.8339\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 5.6563 - accuracy: 0.8468 - val_loss: 0.4417 - val_accuracy: 0.8365\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.6041 - accuracy: 0.8480 - val_loss: 0.4500 - val_accuracy: 0.8375\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.3687 - accuracy: 0.8519 - val_loss: 0.5443 - val_accuracy: 0.8070\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.3077 - accuracy: 0.8533 - val_loss: 0.4371 - val_accuracy: 0.8401\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 5.1534 - accuracy: 0.8571 - val_loss: 0.4671 - val_accuracy: 0.8315\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 5.0836 - accuracy: 0.8583 - val_loss: 0.4322 - val_accuracy: 0.8448\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 4.9292 - accuracy: 0.8625 - val_loss: 0.4297 - val_accuracy: 0.8436\n",
      "Epoch 28/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 4.8143 - accuracy: 0.8646 - val_loss: 0.4365 - val_accuracy: 0.8417\n",
      "Epoch 29/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 4.7503 - accuracy: 0.8656 - val_loss: 0.4198 - val_accuracy: 0.8490\n",
      "Epoch 30/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 4.5141 - accuracy: 0.8719 - val_loss: 0.4511 - val_accuracy: 0.8345\n",
      "Epoch 31/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 4.4680 - accuracy: 0.8731 - val_loss: 0.4203 - val_accuracy: 0.8512\n",
      "Epoch 32/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 4.4142 - accuracy: 0.8732 - val_loss: 0.4409 - val_accuracy: 0.8428\n",
      "Epoch 33/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 4.2519 - accuracy: 0.8769 - val_loss: 0.4417 - val_accuracy: 0.8451\n",
      "Epoch 34/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 4.2935 - accuracy: 0.8754 - val_loss: 0.4503 - val_accuracy: 0.8407\n",
      "2975/2975 [==============================] - 18s 5ms/step\n",
      "372/372 [==============================] - 2s 6ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "250 0 (40.86, 2.8775684179529075) 0.8749519781324036\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 28s 25ms/step - loss: 20.4627 - accuracy: 0.4109 - val_loss: 1.4062 - val_accuracy: 0.5233\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 16.2496 - accuracy: 0.5494 - val_loss: 1.1131 - val_accuracy: 0.6135\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 14.3717 - accuracy: 0.6011 - val_loss: 1.1030 - val_accuracy: 0.6077\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 13.0812 - accuracy: 0.6344 - val_loss: 0.9438 - val_accuracy: 0.6619\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 11.9418 - accuracy: 0.6682 - val_loss: 0.8440 - val_accuracy: 0.6901\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 10.9599 - accuracy: 0.6959 - val_loss: 0.7772 - val_accuracy: 0.7146\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 10.1410 - accuracy: 0.7215 - val_loss: 0.6854 - val_accuracy: 0.7483\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 9.5003 - accuracy: 0.7389 - val_loss: 0.6596 - val_accuracy: 0.7579\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 8.8874 - accuracy: 0.7592 - val_loss: 0.8145 - val_accuracy: 0.6998\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 8.4998 - accuracy: 0.7688 - val_loss: 0.5831 - val_accuracy: 0.7873\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 8.0166 - accuracy: 0.7852 - val_loss: 0.5957 - val_accuracy: 0.7806\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 7.7345 - accuracy: 0.7938 - val_loss: 0.5483 - val_accuracy: 0.7984\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 7.3361 - accuracy: 0.8038 - val_loss: 0.5612 - val_accuracy: 0.7954\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 7.0632 - accuracy: 0.8096 - val_loss: 0.5493 - val_accuracy: 0.8002\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 6.8458 - accuracy: 0.8163 - val_loss: 0.5432 - val_accuracy: 0.8017\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 6.6654 - accuracy: 0.8205 - val_loss: 0.4919 - val_accuracy: 0.8216\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.4088 - accuracy: 0.8276 - val_loss: 0.5189 - val_accuracy: 0.8092\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 17s 22ms/step - loss: 6.2243 - accuracy: 0.8317 - val_loss: 0.5062 - val_accuracy: 0.8133\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744/744 [==============================] - 17s 23ms/step - loss: 6.0738 - accuracy: 0.8346 - val_loss: 0.4851 - val_accuracy: 0.8233\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 5.9170 - accuracy: 0.8395 - val_loss: 0.4555 - val_accuracy: 0.8335\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 5.6971 - accuracy: 0.8440 - val_loss: 0.4845 - val_accuracy: 0.8244\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 5.5972 - accuracy: 0.8463 - val_loss: 0.4718 - val_accuracy: 0.8252\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 5.4307 - accuracy: 0.8502 - val_loss: 0.4500 - val_accuracy: 0.8356\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 5.2742 - accuracy: 0.8552 - val_loss: 0.4649 - val_accuracy: 0.8321\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 5.1771 - accuracy: 0.8559 - val_loss: 0.5051 - val_accuracy: 0.8211\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 17s 23ms/step - loss: 5.0227 - accuracy: 0.8588 - val_loss: 0.4371 - val_accuracy: 0.8443\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.9354 - accuracy: 0.8614 - val_loss: 0.4284 - val_accuracy: 0.8467\n",
      "Epoch 28/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.7333 - accuracy: 0.8661 - val_loss: 0.4666 - val_accuracy: 0.8341\n",
      "Epoch 29/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.6939 - accuracy: 0.8671 - val_loss: 0.4228 - val_accuracy: 0.8513\n",
      "Epoch 30/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.4928 - accuracy: 0.8700 - val_loss: 0.4261 - val_accuracy: 0.8501\n",
      "Epoch 31/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.4415 - accuracy: 0.8729 - val_loss: 0.4429 - val_accuracy: 0.8463\n",
      "Epoch 32/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.3210 - accuracy: 0.8748 - val_loss: 0.4563 - val_accuracy: 0.8456\n",
      "Epoch 33/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.3019 - accuracy: 0.8759 - val_loss: 0.4347 - val_accuracy: 0.8438\n",
      "Epoch 34/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.2282 - accuracy: 0.8779 - val_loss: 0.4705 - val_accuracy: 0.8376\n",
      "2975/2975 [==============================] - 18s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "250 1 (44.22, 2.780575480004095) 0.908311256109165\n",
      "Epoch 1/40\n",
      "744/744 [==============================] - 24s 24ms/step - loss: 20.2774 - accuracy: 0.4217 - val_loss: 1.4236 - val_accuracy: 0.4966\n",
      "Epoch 2/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 15.9842 - accuracy: 0.5564 - val_loss: 1.2099 - val_accuracy: 0.5691\n",
      "Epoch 3/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 14.1057 - accuracy: 0.6091 - val_loss: 0.9937 - val_accuracy: 0.6464\n",
      "Epoch 4/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 12.7656 - accuracy: 0.6452 - val_loss: 0.8895 - val_accuracy: 0.6823\n",
      "Epoch 5/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 11.5037 - accuracy: 0.6794 - val_loss: 0.8101 - val_accuracy: 0.7036\n",
      "Epoch 6/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 10.4421 - accuracy: 0.7109 - val_loss: 0.7395 - val_accuracy: 0.7215\n",
      "Epoch 7/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.7311 - accuracy: 0.7342 - val_loss: 0.6465 - val_accuracy: 0.7664\n",
      "Epoch 8/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 9.1087 - accuracy: 0.7528 - val_loss: 0.6434 - val_accuracy: 0.7595\n",
      "Epoch 9/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.6382 - accuracy: 0.7667 - val_loss: 0.6047 - val_accuracy: 0.7795\n",
      "Epoch 10/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 8.2286 - accuracy: 0.7784 - val_loss: 0.6192 - val_accuracy: 0.7750\n",
      "Epoch 11/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.8276 - accuracy: 0.7876 - val_loss: 0.5442 - val_accuracy: 0.8069\n",
      "Epoch 12/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.4477 - accuracy: 0.8006 - val_loss: 0.5801 - val_accuracy: 0.7849\n",
      "Epoch 13/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 7.2473 - accuracy: 0.8066 - val_loss: 0.5228 - val_accuracy: 0.8090\n",
      "Epoch 14/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.9347 - accuracy: 0.8146 - val_loss: 0.5003 - val_accuracy: 0.8143\n",
      "Epoch 15/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.6176 - accuracy: 0.8216 - val_loss: 0.5440 - val_accuracy: 0.8017\n",
      "Epoch 16/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.4367 - accuracy: 0.8268 - val_loss: 0.4918 - val_accuracy: 0.8203\n",
      "Epoch 17/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.3207 - accuracy: 0.8302 - val_loss: 0.4499 - val_accuracy: 0.8390\n",
      "Epoch 18/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 6.1370 - accuracy: 0.8332 - val_loss: 0.4918 - val_accuracy: 0.8195\n",
      "Epoch 19/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.9259 - accuracy: 0.8388 - val_loss: 0.4529 - val_accuracy: 0.8359\n",
      "Epoch 20/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.7858 - accuracy: 0.8413 - val_loss: 0.5144 - val_accuracy: 0.8148\n",
      "Epoch 21/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.5931 - accuracy: 0.8467 - val_loss: 0.4375 - val_accuracy: 0.8411\n",
      "Epoch 22/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.4949 - accuracy: 0.8477 - val_loss: 0.4272 - val_accuracy: 0.8494\n",
      "Epoch 23/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.3249 - accuracy: 0.8534 - val_loss: 0.4327 - val_accuracy: 0.8442\n",
      "Epoch 24/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.1845 - accuracy: 0.8558 - val_loss: 0.4422 - val_accuracy: 0.8411\n",
      "Epoch 25/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.1043 - accuracy: 0.8586 - val_loss: 0.4401 - val_accuracy: 0.8438\n",
      "Epoch 26/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 5.0056 - accuracy: 0.8600 - val_loss: 0.4494 - val_accuracy: 0.8385\n",
      "Epoch 27/40\n",
      "744/744 [==============================] - 16s 22ms/step - loss: 4.8460 - accuracy: 0.8636 - val_loss: 0.4314 - val_accuracy: 0.8447\n",
      "2975/2975 [==============================] - 17s 5ms/step\n",
      "372/372 [==============================] - 2s 5ms/step\n",
      "1711/1711 [==============================] - 7s 4ms/step\n",
      "250 2 (43.66, 2.8114764804280328) 0.9049695749165818\n"
     ]
    }
   ],
   "source": [
    "for i in range(140, 260, 10):\n",
    "    for _ in range(3):\n",
    "        \n",
    "        model = train_model(i, True)\n",
    "#         model = load(f'Latent{i}')\n",
    "        latent_model = Model(inputs=[model.get_layer('lc').input, model.get_layer('host').input], outputs=model.get_layer('latent').output)\n",
    "        train_pred = latent_model.predict([X_train, host_gal_train])\n",
    "\n",
    "        detector = mcif(n_estimators=200)\n",
    "        detector.train(train_pred, y_train)\n",
    "\n",
    "        test_latent = (latent_model.predict([X_test, host_gal_test]))\n",
    "        test_pred = detector.score(test_latent)\n",
    "\n",
    "        anom_pred = detector.score((latent_model.predict([x_data_anom, host_gal_anom])))\n",
    "\n",
    "\n",
    "        rec.append(plot_recall(test_pred, anom_pred, ret=True))\n",
    "        aurocs.append(auroc(test_pred, anom_pred)[0])\n",
    "        szs.append(i)\n",
    "        print(i, _, rec[-1], aurocs[-1])\n",
    "\n",
    "#         save(f'models/Latent{i}', model)\n",
    "    save('hyper/aurocs', aurocs)\n",
    "    save('hyper/szs', szs)\n",
    "    save('hyper/recall', rec)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "oth = np.unique(szs)\n",
    "oth_aurocs = []\n",
    "err = []\n",
    "aurocs = np.array(aurocs)\n",
    "szs = np.array(szs)\n",
    "\n",
    "for i in oth:\n",
    "    oth_aurocs.append(np.mean(aurocs[szs==i]))\n",
    "    err.append(np.std(aurocs[szs==i]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.errorbar(oth, oth_aurocs, yerr=err, fmt='o')\n",
    "\n",
    "plt.ylabel('AUROC', fontsize=20)\n",
    "plt.xlabel('Latent Size', fontsize=20)\n",
    "\n",
    "saveplot('Figures/latentauroc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
